# api/funds.py
# FINTABLES KALÄ°TESÄ°NDE FON DETAY SCRAPER (KAP + TEFAS)
# %100 Ã‡ALIÅAN VERSÄ°YON - FULL FILE

from __future__ import annotations

import os
import json
import time
import threading
import math
import re
import requests
import urllib3
import yfinance as yf
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional
from bs4 import BeautifulSoup  # HTML Parsing iÃ§in

try:
    from zoneinfo import ZoneInfo
except Exception:
    ZoneInfo = None

from fastapi import APIRouter

# âœ… EKLENDÄ°: Premium AI araÃ§larÄ± (summary iÃ§in)
from api.premium_ai import (
    build_premium_prediction as premium_build_prediction,
    load_funds_master_map,
    read_market_snapshot,
    market_change_pct,
)

# SSL UyarÄ±larÄ±nÄ± Kapat
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

router = APIRouter(tags=["funds"])

# ============================================================
# 1. AYARLAR & GLOBAL HAFIZA (OTOMATÄ°K ROOT TESPÄ°TÄ°)
# ============================================================

def _detect_project_root() -> str:
    """
    funds.py hangi klasÃ¶rde olursa olsun proje root'unu bulmaya Ã§alÄ±ÅŸÄ±r.
    Ã–ncelik: iÃ§inde funds_cache veya data klasÃ¶rÃ¼ olan Ã¼st dizin.
    """
    here = os.path.abspath(os.path.dirname(__file__))
    candidates = [
        os.path.abspath(os.path.join(here, "..")),        # 1 Ã¼st
        os.path.abspath(os.path.join(here, "..", "..")),  # 2 Ã¼st
        os.path.abspath(os.path.join(here, "..", "..", "..")),  # 3 Ã¼st
    ]
    for c in candidates:
        if os.path.isdir(os.path.join(c, "funds_cache")) or os.path.isdir(os.path.join(c, "data")):
            return c
    # fallback
    return candidates[0]

BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))

CACHE_ROOT = os.getenv(
    "CACHE_ROOT",
    BASE_DIR  # local default
)

CACHE_DIR = os.path.join(CACHE_ROOT, "funds_cache")
os.makedirs(CACHE_DIR, exist_ok=True)

# âœ… DATA DIR (HER ZAMAN PROJE Ä°Ã‡Ä°NDE)
DATA_DIR = os.path.join(BASE_DIR, "data")
os.makedirs(DATA_DIR, exist_ok=True)

FUNDS_MASTER_PATH = os.path.join(DATA_DIR, "funds_master.json")
LIVE_PRICES_PATH = os.path.join(CACHE_DIR, "live_prices.json")
# âœ… HÄ°SSE FÄ°YATLARI Ä°Ã‡Ä°N (AI HESAPLAMASINDA KULLANILACAK)
STOCKS_LIVE_PRICES_PATH = os.path.join(DATA_DIR, "live_prices.json") 

PORTFOLIO_PATH = os.path.join(CACHE_DIR, "portfolio.json")
MARKET_CACHE_PATH = os.path.join(CACHE_DIR, "market_cache.json")
PREDICTION_CACHE_PATH = os.path.join(CACHE_DIR, "prediction_cache.json")

# âœ… YENÄ°: CanlÄ± liste dosyasÄ±
LIVE_LIST_PATH = os.path.join(CACHE_DIR, "live_list.json")

# âœ… YENÄ°: PortfÃ¶y gÃ¼ncelleme durumu iÃ§in dosya yolu
PORTFOLIO_UPDATE_STATE_PATH = os.path.join(CACHE_DIR, "portfolio_update_state.json")
# âœ… YENÄ°: CanlÄ± liste gÃ¼ncelleme durumu iÃ§in dosya yolu
LIVE_LIST_UPDATE_STATE_PATH = os.path.join(CACHE_DIR, "live_list_update_state.json")

# âœ… YENÄ°: Fetch Tracking Path (Tekrar Ã§ekimi Ã¶nlemek iÃ§in - ArtÄ±k logic iÃ§inde kullanÄ±lmÄ±yor ama dosya tanÄ±mÄ± kalsÄ±n)
FETCH_TRACKING_PATH = os.path.join(CACHE_DIR, "fetch_tracking.json")

os.makedirs(CACHE_DIR, exist_ok=True)
os.makedirs(DATA_DIR, exist_ok=True)

# RAM CACHE (TEFAS iÃ§in)
_PRICE_CACHE: Dict[str, Dict] = {}
_TEFAS_LOCK = threading.Lock()

# AI TAHMÄ°N CACHE (TEFAS'SIZ, 5 sn)
_AI_CACHE: Dict[str, Dict[str, Any]] = {}
_AI_LOCK = threading.Lock()

# ğŸ”’ Direction Lock Cache
_AI_DIRECTION_LOCK: Dict[str, Dict[str, Any]] = {}

# âœ… EKLENDÄ°: funds_master map cache (type/name iÃ§in)
_MASTER_MAP: Dict[str, Dict[str, Any]] = {}
_MASTER_MAP_TS: float = 0.0
_MASTER_LOCK = threading.Lock()
_MASTER_TTL_SEC = 3600  # 1 saat

# âœ… EKLENDÄ°: Predictions Summary cache (Ã§ok hÄ±zlÄ± UI iÃ§in)
_PRED_SUMMARY_CACHE: Dict[str, Any] = {}
# âœ… PATCH 3.1 & 3.2: Timestamp artÄ±k dict (scope bazlÄ±)
_PRED_SUMMARY_TS: Dict[str, float] = {}
_PRED_SUMMARY_LOCK = threading.Lock()
_PRED_SUMMARY_TTL_SEC = 15  # 15 sn cache (UI refresh iÃ§in yeterli)

# ================================
# ğŸ”’ Background jobs start guard (uvicorn --reload safe)
# ================================
# âœ… PATCH 0.1: Tek seferlik baÅŸlatma kilidi
_BG_STARTED = False
_BG_LOCK = threading.Lock()

# ================================
# GÃœNLÄ°K PORTFÃ–Y & CANLI LÄ°STE UPDATE KÄ°LÄ°DÄ°
# ================================
_PORTFOLIO_UPDATE_LOCK = threading.Lock()
_LIVE_LIST_UPDATE_LOCK = threading.Lock()

# ============================================================
# 2. YARDIMCI FONKSÄ°YONLAR
# ============================================================

# âœ… GÃœNCELLENDÄ°: now_str() Istanbul saatine gÃ¶re
def now_str() -> str:
    try:
        if ZoneInfo:
            return datetime.now(ZoneInfo("Europe/Istanbul")).strftime("%Y-%m-%d %H:%M:%S")
    except:
        pass
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


# âœ… GÃœNCELLENDÄ°: today_str() Istanbul saatine gÃ¶re
def today_str() -> str:
    try:
        if ZoneInfo:
            return datetime.now(ZoneInfo("Europe/Istanbul")).strftime("%Y-%m-%d")
    except:
        pass
    return datetime.now().strftime("%Y-%m-%d")

# âœ… YARDIMCI: Ã–nceki iÅŸ gÃ¼nÃ¼nÃ¼ bul
def _prev_business_day(d):
    d = d - timedelta(days=1)
    while d.weekday() >= 5:  # 5=Sat, 6=Sun
        d = d - timedelta(days=1)
    return d

# âœ… DÃœZELTÄ°LDÄ°: TEFAS Effective Date (Haftasonu + 09:30 KuralÄ±)
def tefas_effective_date() -> str:
    try:
        now = datetime.now(ZoneInfo("Europe/Istanbul"))
    except:
        now = datetime.now()

    today = now.date()
    after_0930 = (now.hour > 9) or (now.hour == 9 and now.minute >= 30)

    if today.weekday() >= 5:
        # Hafta sonu: TEFAS hÃ¢lÃ¢ PerÅŸembe'yi verir (Cuma verisi â€œyayÄ±nlanmÄ±ÅŸâ€ sayÄ±lmaz)
        d = _prev_business_day(_prev_business_day(today))
    else:
        if after_0930:
            # 09:30 sonrasÄ±: dÃ¼nÃ¼n iÅŸ gÃ¼nÃ¼
            d = _prev_business_day(today)
        else:
            # 09:30 Ã¶ncesi: iki Ã¶nceki iÅŸ gÃ¼nÃ¼
            d = _prev_business_day(_prev_business_day(today))

    return d.strftime("%Y-%m-%d")

# âœ… YENÄ°: PortfÃ¶y gÃ¼ncelleme durumu iÃ§in dosya yolu
def _load_portfolio_update_day() -> Optional[str]:
    if os.path.exists(PORTFOLIO_UPDATE_STATE_PATH):
        try:
            with open(PORTFOLIO_UPDATE_STATE_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
                return data.get("last_day")
        except:
            pass
    return None

# âœ… YENÄ°: PortfÃ¶y gÃ¼ncelleme durumu diske yaz
def _save_portfolio_update_day(day: str):
    try:
        with open(PORTFOLIO_UPDATE_STATE_PATH, "w", encoding="utf-8") as f:
            json.dump({"last_day": day}, f, ensure_ascii=False)
    except:
        pass

# âœ… YENÄ°: CanlÄ± liste gÃ¼ncelleme durumu diskten oku (Optional ile uyumlu)
def _load_live_list_update_day() -> Optional[str]:
    if os.path.exists(LIVE_LIST_UPDATE_STATE_PATH):
        try:
            with open(LIVE_LIST_UPDATE_STATE_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
                return data.get("last_day")
        except:
            pass
    return None

# âœ… YENÄ°: CanlÄ± liste gÃ¼ncelleme durumu diske yaz
def _save_live_list_update_day(day: str):
    try:
        with open(LIVE_LIST_UPDATE_STATE_PATH, "w", encoding="utf-8") as f:
            json.dump({"last_day": day}, f, ensure_ascii=False)
    except:
        pass

# âœ… YENÄ°: FETCH TRACKING HELPER'LARI (ArtÄ±k aktif kullanÄ±lmÄ±yor ama dosya tanÄ±mÄ± kalsÄ±n)
def _load_fetch_tracking() -> Dict[str, str]:
    if os.path.exists(FETCH_TRACKING_PATH):
        try:
            with open(FETCH_TRACKING_PATH, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            pass
    return {}

def _save_fetch_tracking(data: Dict[str, str]):
    try:
        with open(FETCH_TRACKING_PATH, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except:
        pass

# âœ… GÃœNCELLENDÄ°: RAM CACHE Ä°Ã‡Ä°NDE GÃœNCEL VERÄ° KONTROLÃœ (asof_day bazlÄ±)
def _is_code_fresh(code: str, effective_day: str) -> bool:
    """
    Bir fon kodu effective_day iÃ§in gÃ¼ncel mi?
    - asof_day kontrol edilir.
    - RAM cache'e bakar, yoksa disk cache'ten bakar.
    """
    code = code.upper().strip()

    def check_rec(r: Dict) -> bool:
        if not r or r.get("nav", 0) <= 0:
            return False
        # âœ… Ã–ncelik asof_day
        rec_asof = str(r.get("asof_day") or "").strip()
        if rec_asof == effective_day:
            return True
        # asof_day yoksa (eski veri) ama last_update tutuyorsa (legacy)
        if not rec_asof and str(r.get("last_update", "")).startswith(effective_day):
            return True
        return False

    # 1) RAM check
    if check_rec(_PRICE_CACHE.get(code)):
        return True

    # 2) Disk check
    if os.path.exists(LIVE_PRICES_PATH):
        try:
            with open(LIVE_PRICES_PATH, "r", encoding="utf-8") as f:
                disk_raw = json.load(f)
            disk_data = disk_raw.get("data", {}) if isinstance(disk_raw, dict) else {}
            if check_rec(disk_data.get(code)):
                return True
        except:
            pass

    return False

def _missing_codes_for_day(codes: List[str], effective_day: str) -> List[str]:
    """codes iÃ§inden effective_day iÃ§in gÃ¼ncel olmayanlarÄ± dÃ¶ndÃ¼rÃ¼r."""
    out = []
    for c in codes:
        c2 = (c or "").upper().strip()
        if c2 and not _is_code_fresh(c2, effective_day):
            out.append(c2)
    return out

# âœ… YENÄ°: CanlÄ± listeden fon kodlarÄ±nÄ± oku
def _get_live_list_codes() -> List[str]:
    """CanlÄ± listedeki fon kodlarÄ±nÄ± dÃ¶ndÃ¼r"""
    codes = []
    if os.path.exists(LIVE_LIST_PATH):
        try:
            with open(LIVE_LIST_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
            for item in data.get("items", []):
                code = str(item.get("code") or "").upper().strip()
                if code:
                    codes.append(code)
        except:
            pass
    return codes

# âœ… YENÄ°: PortfÃ¶yden fon kodlarÄ±nÄ± oku
def _get_portfolio_codes() -> List[str]:
    """PortfÃ¶ydeki fon kodlarÄ±nÄ± dÃ¶ndÃ¼r"""
    codes = []
    if os.path.exists(PORTFOLIO_PATH):
        try:
            with open(PORTFOLIO_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
            for pos in data.get("positions", []):
                code = str(pos.get("code") or "").upper().strip()
                if code:
                    codes.append(code)
        except:
            pass
    return codes

# âœ… YENÄ°: Ä°lk defa eklenen fonlarÄ± tespit et
def _get_newly_added_funds(previous_codes: List[str], current_codes: List[str]) -> List[str]:
    """Yeni eklenen fon kodlarÄ±nÄ± dÃ¶ndÃ¼r"""
    prev_set = set(previous_codes)
    new_codes = [code for code in current_codes if code not in prev_set]
    return new_codes

# ğŸ“Œ DÃœZELTME 1: Unicode eksi iÅŸareti ve temizleme mantÄ±ÄŸÄ± gÃ¼ncellendi
def _parse_turkish_float(text: str) -> float:
    try:
        s = str(text).strip()
        s = s.replace("âˆ’", "-")  # unicode minus
        s = s.replace("%", "")
        # Ã–rn: 1.234,56 -> Ã¶nce noktayÄ± sil, virgÃ¼lÃ¼ nokta yap
        if "," in s and "." in s:
            s = s.replace(".", "").replace(",", ".")
        elif "," in s:
            s = s.replace(",", ".")
        
        # Sadece sayÄ±, nokta ve eksi kalsÄ±n
        s = re.sub(r"[^0-9.-]", "", s)
        return float(s)
    except:
        return 0.0

# âœ… DÃœZELTÄ°LDÄ°: 1ï¸âƒ£ load_cache_to_memory()
def load_cache_to_memory():
    """Server aÃ§Ä±lÄ±nca diskteki veriyi RAM'e yÃ¼kler"""
    global _PRICE_CACHE
    
    if not os.path.exists(LIVE_PRICES_PATH):
        _PRICE_CACHE = {}
    else:
        try:
            with open(LIVE_PRICES_PATH, "r", encoding="utf-8") as f:
                raw = json.load(f)

            # âœ… KRÄ°TÄ°K: batch output iÃ§inden SADECE data'yÄ± al
            if isinstance(raw, dict) and "data" in raw:
                _PRICE_CACHE = raw["data"]
            else:
                _PRICE_CACHE = raw

            print(f"âœ… RAM cache yÃ¼klendi: {len(_PRICE_CACHE)} fon")

        except Exception as e:
            print(f"âŒ Cache yÃ¼klenedi: {e}")
            _PRICE_CACHE = {}

    # âœ… DEBUG PRINTS (Ä°STENÄ°LEN)
    print(f"ğŸ§­ BASE_DIR={BASE_DIR}")
    print(f"ğŸ§­ PORTFOLIO_PATH={PORTFOLIO_PATH} exists={os.path.exists(PORTFOLIO_PATH)}")
    print(f"ğŸ§­ LIVE_LIST_PATH={LIVE_LIST_PATH} exists={os.path.exists(LIVE_LIST_PATH)}")
    print(f"ğŸ§­ LIVE_PRICES_PATH={LIVE_PRICES_PATH} exists={os.path.exists(LIVE_PRICES_PATH)}")

# âœ… ADIM 3: KAYIT FORMATI DÃœZELTÄ°LDÄ° (Batch scraper uyumlu)
def save_memory_to_disk():
    """RAM cache'i diske atomik yaz"""
    try:
        tmp = LIVE_PRICES_PATH + ".tmp"
        with open(tmp, "w", encoding="utf-8") as f:
            json.dump(
                {"data": _PRICE_CACHE, "asof": now_str()},
                f,
                ensure_ascii=False,
                indent=2
            )
        os.replace(tmp, LIVE_PRICES_PATH)
    except Exception as e:
        print(f"âŒ save_memory_to_disk: {e}")

# âœ… PATCH 1.1: Atomik JSON yazma helper'Ä±
def _atomic_write_json(path: str, obj: Any):
    """JSON'u atomik yaz (yarÄ±m dosya / bozuk JSON riskini azaltÄ±r)."""
    try:
        tmp = path + ".tmp"
        with open(tmp, "w", encoding="utf-8") as f:
            json.dump(obj, f, ensure_ascii=False, indent=2)
        os.replace(tmp, path)
    except Exception as e:
        print(f"âŒ _atomic_write_json({path}): {e}")

# âœ… EKLENDÄ°: master map'i cacheli oku (type/name iÃ§in)
def _get_master_map_cached() -> Dict[str, Dict[str, Any]]:
    global _MASTER_MAP, _MASTER_MAP_TS
    ts = time.time()
    if _MASTER_MAP and (ts - _MASTER_MAP_TS) < _MASTER_TTL_SEC:
        return _MASTER_MAP

    with _MASTER_LOCK:
        ts = time.time()
        if _MASTER_MAP and (ts - _MASTER_MAP_TS) < _MASTER_TTL_SEC:
            return _MASTER_MAP
        _MASTER_MAP = load_funds_master_map(FUNDS_MASTER_PATH)
        _MASTER_MAP_TS = ts
        return _MASTER_MAP

# ============================================================
# 3. VERÄ° Ã‡EKME MOTORU (TEFAS & KAP - Ä°Å YATIRIM)
# ============================================================

def _fetch_html_tefas(fund_code: str):
    """TEFAS Ana SayfasÄ±ndan Fiyat ve Getiri Verisi"""
    print(f"ğŸŒ TEFAS HTML deniyorum: {fund_code}")
    url = f"https://www.tefas.gov.tr/FonAnaliz.aspx?FonKod={fund_code.upper()}"
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"}
    
    try:
        r = requests.get(url, headers=headers, timeout=10, verify=False)
        if r.status_code == 200:
            price, daily, yearly = 0.0, 0.0, 0.0
            
            # Fiyat
            m = re.search(r"Son Fiyat.*?<span>([\d,\.]+)</span>", r.text, re.DOTALL)
            if m: price = _parse_turkish_float(m.group(1))
            
            # GÃ¼nlÃ¼k
            m = re.search(r"GÃ¼nlÃ¼k Getiri.*?<span>(.*?)</span>", r.text, re.DOTALL)
            if m: daily = _parse_turkish_float(m.group(1))
            
            # YÄ±llÄ±k
            m = re.search(r"Son 1 YÄ±l.*?<span>(.*?)</span>", r.text, re.DOTALL)
            if m: yearly = _parse_turkish_float(m.group(1))
            
            if price > 0:
                return {"price": price, "daily_pct": daily, "yearly_pct": yearly, "source": "HTML"}
    except Exception as e:
        print(f"âŒ TEFAS HTML Hata: {e}")
    return None

def _fetch_api_tefas(fund_code: str):
    """TEFAS API Yedek (Fiyat iÃ§in)"""
    url = "https://www.tefas.gov.tr/api/DB/BindHistoryInfo"
    try:
        end = datetime.now()
        start = end - timedelta(days=7)
        payload = {
            "fontip": "YAT",
            "fonkod": fund_code.upper(),
            "bastarih": start.strftime("%d.%m.%Y"),
            "bittarih": end.strftime("%d.%m.%Y"),
        }
        r = requests.post(url, data=payload, timeout=10, verify=False)
        if r.status_code == 200:
            data = r.json().get("data", [])
            if data:
                # En son tarihi bul
                valid = []
                for i in data:
                    # Tarih parse (Unix ms timestamp geliyor genelde)
                    ts = i.get("TARIH", 0)
                    if ts: valid.append(i)
                
                if valid:
                    # Tarihe gÃ¶re sÄ±rala (en bÃ¼yÃ¼k tarih en baÅŸa)
                    # "TARIH" alanÄ± genellikle timestamp (long) gelir.
                    valid.sort(key=lambda x: x.get("TARIH", 0), reverse=True)
                    
                    last = valid[0] 
                    price = _parse_turkish_float(last.get("FIYAT", 0))
                    if price > 0:
                        return {"price": price, "daily_pct": None, "yearly_pct": 0.0, "source": "API", "asof_day": datetime.fromtimestamp(last.get("TARIH", 0)/1000).strftime("%Y-%m-%d")}
    except:
        pass
    return None

def fetch_fund_live(fund_code: str):
    html = _fetch_html_tefas(fund_code)
    if html: return html
    api = _fetch_api_tefas(fund_code)
    if api: return api
    return None

# ============================================================
# ğŸ”¥ YENÄ°: KAP (Ä°Å YATIRIM) & TEFAS (PASTA) SCRAPER
# ============================================================

def _fetch_tefas_allocation(fund_code: str) -> Optional[List[Dict[str, Any]]]:
    """TEFAS'tan VarlÄ±k DaÄŸÄ±lÄ±mÄ±nÄ± (Pasta Grafik) Ã§eker"""
    print(f"ğŸ¥§ TEFAS Allocation deniyorum: {fund_code}")
    url = f"https://www.tefas.gov.tr/FonAnaliz.aspx?FonKod={fund_code.upper()}"
    headers = {"User-Agent": "Mozilla/5.0"}

    try:
        r = requests.get(url, headers=headers, timeout=10, verify=False)
        if r.status_code == 200:
            # Regex ile Highcharts verisini bul: data: [['Hisse', 20], ['Mevduat', 80]]
            match = re.search(r"data:\s*(\[\[.*?\]\])", r.text)
            if match:
                raw = match.group(1).replace("'", '"')
                try:
                    data = json.loads(raw)
                    # [["Hisse", 20], ["Mevduat", 80]] -> [{"name":"Hisse","value":20}, ...]
                    return [{"name": i[0], "value": float(i[1])} for i in data if len(i) == 2 and float(i[1]) > 0]
                except:
                    pass
    except Exception as e:
        print(f"âŒ TEFAS Allocation HatasÄ±: {e}")
    
    return None

def _fetch_kap_portfolio_from_isyatirim(fund_code: str) -> Optional[Dict[str, Any]]:
    """
    Ä°ÅŸ YatÄ±rÄ±m Fon Detay SayfasÄ±ndan KAP Verilerini Ã‡eker (Resmi Kaynak Scraper)
    """
    print(f"ğŸ›ï¸ Ä°ÅŸ YatÄ±rÄ±m (KAP) Verisi Ã‡ekiliyor: {fund_code}")
    
    url = f"https://www.isyatirim.com.tr/tr-tr/analiz/fonlar/Sayfalar/Fon-Detay.aspx?FonKodu={fund_code.upper()}"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36"
    }
    
    try:
        r = requests.get(url, headers=headers, timeout=12)
        if r.status_code != 200: return None
        
        soup = BeautifulSoup(r.text, "html.parser")
        details = {
            "positions": [],
            "info": {"risk_value": 4, "founder": ""}, # Default deÄŸerler
            "allocation": [] 
        }
        
        # 1. KURUCU BÄ°LGÄ°SÄ° (H1 BaÅŸlÄ±ÄŸÄ±ndan veya Breadcrumb'dan)
        # Genelde sayfa baÅŸlÄ±ÄŸÄ±: "Fon Detay - AFT - AK PORTFÃ–Y YENÄ° TEKNOLOJÄ°LER..."
        h1 = soup.find("div", {"class": "page-title"})
        if h1:
            raw_title = h1.get_text(strip=True)
            # Koddan sonrasÄ±nÄ± al
            if fund_code.upper() in raw_title:
                parts = raw_title.split(fund_code.upper())
                if len(parts) > 1:
                    details["info"]["founder"] = parts[1].strip(" -")
        
        # 2. RÄ°SK DEÄERÄ° (Tablo veya Metin Ä°Ã§inde Ara)
        # Ä°ÅŸ YatÄ±rÄ±m'da "Risk DeÄŸeri" genelde bir label veya td iÃ§indedir.
        risk_elem = soup.find(string=re.compile("Risk DeÄŸeri"))
        if risk_elem:
            try:
                # Parent container'a bak
                parent = risk_elem.find_parent("tr") or risk_elem.find_parent("div")
                if parent:
                    txt = parent.get_text(strip=True)
                    match = re.search(r"Risk DeÄŸeri.*?(\d)", txt)
                    if match:
                        details["info"]["risk_value"] = int(match.group(1))
            except:
                pass

        # 3. EN BÃœYÃœK POZÄ°SYONLAR (Tablo Analizi)
        # Sayfadaki tÃ¼m tablolarÄ± gez, baÅŸlÄ±ÄŸÄ±nda "Menkul" veya "Kod" ve "Oran" geÃ§en tabloyu bul.
        tables = soup.find_all("table")
        for table in tables:
            headers_text = [th.get_text(strip=True).lower() for th in table.find_all("th")]
            
            is_pos_table = (
                (any("kod" in h for h in headers_text) or any("menkul" in h for h in headers_text)) and
                (any("oran" in h for h in headers_text) or any("%" in h for h in headers_text) or any("daÄŸÄ±lÄ±m" in h for h in headers_text))
            )
            
            if is_pos_table:
                rows = table.find_all("tr")[1:] # Header hariÃ§
                for row in rows:
                    cols = row.find_all("td")
                    if len(cols) >= 2:
                        name_code = cols[0].get_text(strip=True)
                        ratio_str = cols[1].get_text(strip=True)
                        
                        if not ratio_str: continue

                        ratio = _parse_turkish_float(ratio_str)
                        # Temiz kod: "THYAO" veya "AKBNK Hisse" -> "THYAO"
                        clean_code = name_code.split()[0].strip().upper()
                        
                        # Filtreleme: TOPLAM, Mevduat vb. hariÃ§, sadece anlamlÄ± oranlar
                        if "TOPLAM" in clean_code or len(clean_code) < 3: continue
                        if ratio > 0.1: # %0.1 altÄ±nÄ± alma
                            details["positions"].append({"code": clean_code, "ratio": ratio})
                
                if details["positions"]: break # Tabloyu bulduk, dÃ¶ngÃ¼den Ã§Ä±k

        print(f"âœ… Ä°ÅŸ YatÄ±rÄ±m Data: {len(details['positions'])} pozisyon, Risk: {details['info']['risk_value']}")
        return details

    except Exception as e:
        print(f"âŒ Ä°ÅŸ YatÄ±rÄ±m Scraping Error: {e}")
        return None

# ============================================================
# ğŸ”¥ YENÄ°: HÄ°SSE BAZLI AI SKORLAMA (LIVE STOCK DATA ILE)
# ============================================================
def _load_live_stocks() -> Dict[str, float]:
    """Services.py tarafÄ±ndan Ã¼retilen hisse fiyatlarÄ±nÄ± okur"""
    prices = {}
    if os.path.exists(STOCKS_LIVE_PRICES_PATH):
        try:
            with open(STOCKS_LIVE_PRICES_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
                if isinstance(data, list):
                    for item in data:
                        sym = item.get("symbol", "").replace(".IS", "")
                        chg = item.get("chgPct", 0.0)
                        prices[sym] = float(chg)
                elif isinstance(data, dict) and "data" in data:
                     for item in data["data"]:
                        sym = item.get("symbol", "").replace(".IS", "")
                        chg = item.get("chgPct", 0.0)
                        prices[sym] = float(chg)
        except:
            pass
    return prices

def calculate_ai_prediction(yearly: float, daily: float, holdings: List[Dict[str, Any]] = None):
    """
    YENÄ° NESÄ°L AI TAHMÄ°NÄ°:
    Fonun iÃ§indeki hisselerin anlÄ±k (Live) verilerine gÃ¶re aÄŸÄ±rlÄ±klÄ± tahmin Ã¼retir.
    """
    # 1. Klasik (Baz) Skor (GeÃ§miÅŸ performans)
    d_val = daily if daily is not None else 0.0
    
    direction = "NÃ–TR"
    confidence = 50
    
    # Baz YÃ¶n Belirleme
    if yearly > 40:
        confidence += 20
        direction = "POZÄ°TÄ°F"
    elif yearly < 0:
        confidence += 10
        direction = "NEGATÄ°F"

    # 2. HÄ°SSE BAZLI CANLI SKOR (Kritik BÃ¶lÃ¼m)
    stock_impact = 0.0
    
    if holdings:
        live_stocks = _load_live_stocks()
        if live_stocks:
            total_w = 0.0
            weighted_change = 0.0
            
            for h in holdings:
                code = h.get("code", "")
                ratio = h.get("ratio", 0.0)
                
                live_chg = live_stocks.get(code)
                
                if live_chg is not None:
                    weighted_change += (live_chg * ratio)
                    total_w += ratio
            
            # Fonun NAV Ã¼zerindeki tahmini anlÄ±k etkisi (Hisse bacaÄŸÄ±)
            # Oranlar zaten % olarak geliyor (Ã–rn: 5.4 -> %5.4)
            # Etki = (Hisse DeÄŸiÅŸimi * Hisse OranÄ±) / 100
            
            if total_weight := total_w: # Walrus operator for neatness, or just use total_w
                 pass
            
            # Basit aÄŸÄ±rlÄ±klÄ± ortalama deÄŸil, portfÃ¶ye katkÄ±:
            stock_impact = weighted_change / 100.0 
            
            # YÃ¶nÃ¼ canlÄ± veriye gÃ¶re revize et
            if stock_impact > 0.2:
                direction = "POZÄ°TÄ°F"
                confidence = min(95, confidence + 20)
            elif stock_impact < -0.2:
                direction = "NEGATÄ°F"
                confidence = min(95, confidence + 20)
            elif abs(stock_impact) < 0.1:
                # Yatay seyir
                pass

    # Final Tahmin (Hisse etkisi baskÄ±n, gÃ¼nlÃ¼k veri destekleyici)
    # stock_impact: Tahmini % deÄŸiÅŸim (Ã–rn: +1.5)
    estimated_return = stock_impact
    
    # EÄŸer hisse verisi yoksa veya Ã§ok azsa, eski usul daily'ye dÃ¶n
    if not holdings or stock_impact == 0.0:
        estimated_return = d_val
        
    # YÃ¶n Text Revize
    if estimated_return > 0.15:
        direction = "POZÄ°TÄ°F"
    elif estimated_return < -0.15:
        direction = "NEGATÄ°F"
    else:
        direction = "NÃ–TR"

    return direction, confidence, estimated_return

def get_fund_data_safe(fund_code: str):
    """
    GÃœNDE 1 KEZ TEFAS + KAP ENTEGRASYONLU VERÄ° Ã‡EKER
    """
    fund_code = fund_code.upper()
    effective_day = tefas_effective_date()

    try:
        now = datetime.now(ZoneInfo("Europe/Istanbul"))
    except:
        now = datetime.now()
    before_open = now.hour < 9 or (now.hour == 9 and now.minute < 30)
    is_weekend = now.weekday() >= 5

    cached = _PRICE_CACHE.get(fund_code)

    # Diskten YÃ¼kleme
    if not cached:
        if os.path.exists(LIVE_PRICES_PATH):
            try:
                with open(LIVE_PRICES_PATH, "r", encoding="utf-8") as f:
                    disk_raw = json.load(f)
                disk_data = disk_raw.get("data", {}) if isinstance(disk_raw, dict) else {}
                if disk_data.get(fund_code):
                    cached = disk_data[fund_code]
                    _PRICE_CACHE[fund_code] = cached
            except:
                pass

    cached_asof = (cached.get("asof_day") or "").strip() if cached else ""
    
    # Detay verisi var mÄ± kontrol et
    has_details = False
    if cached and "details" in cached:
        d = cached["details"]
        if d.get("positions") or d.get("info", {}).get("risk_value"):
            has_details = True

    is_new_fund = not cached
    force_fetch = False
    
    if is_new_fund:
        force_fetch = True
    elif not has_details: 
        force_fetch = True 
    elif cached_asof != effective_day:
        force_fetch = True

    # Piyasalar kapalÄ±ysa ve eski veri varsa zorlama (Cache'i koru)
    if (not is_weekend) and before_open and not is_new_fund and has_details:
        force_fetch = False

    if not force_fetch and cached:
        return cached

    # EÄŸer cache yok ve fetch de kapalÄ±ysa boÅŸ dÃ¶n
    if not cached and not force_fetch:
        return {"nav": 0.0, "daily_return_pct": 0.0}

    with _TEFAS_LOCK:
        # Double check inside lock
        cached = _PRICE_CACHE.get(fund_code)
        
        # Tekrar kontrol (Race condition Ã¶nlemi)
        has_details_inner = False
        if cached and "details" in cached:
             if cached["details"].get("positions") or cached["details"].get("info", {}).get("risk_value"):
                 has_details_inner = True

        if cached and cached.get("asof_day") == effective_day and has_details_inner:
            return cached

        print(f"ğŸš€ FORCE FETCH (X-RAY): {fund_code}")

        data = None
        if force_fetch:
            data = fetch_fund_live(fund_code)

        if data and data.get("price", 0) > 0:
            asof_day = (data.get("asof_day") or "").strip()
            if not asof_day:
                api_meta = _fetch_api_tefas(fund_code)
                asof_day = api_meta["asof_day"] if api_meta and "asof_day" in api_meta else effective_day

            safe_daily = data["daily_pct"] if data["daily_pct"] is not None else 0.0

            # ğŸ”¥ YENÄ°: DETAYLARI Ã‡EK (Ä°Å YATIRIM / KAP)
            details = _fetch_kap_portfolio_from_isyatirim(fund_code)
            
            # TEFAS'tan Allocation (Pasta Grafik) al
            allocation = _fetch_tefas_allocation(fund_code)
            
            if details:
                if allocation:
                     details["allocation"] = allocation 
            else:
                # BaÅŸarÄ±sÄ±zsa boÅŸ obje ama allocation varsa ekle
                details = {
                    "positions": [],
                    "info": {},
                    "allocation": allocation if allocation else []
                }

            # ğŸ”¥ YENÄ°: AI Hesapla (Pozisyon verisiyle)
            holdings = details.get("positions", [])
            dir_str, conf, est_ret = calculate_ai_prediction(data["yearly_pct"], safe_daily, holdings)

            new_data = {
                "nav": data["price"],
                "daily_return_pct": safe_daily,
                "asof_day": asof_day,
                "last_update": asof_day + " 18:30:00",
                "source": data.get("source", "HTML"),
                "details": details, # âœ… ZENGÄ°N VERÄ° EKLENDÄ°
                "ai_prediction": {
                    "direction": dir_str,
                    "confidence": conf,
                    "score": round(data["yearly_pct"] / 12, 2),
                    "estimated_return": round(est_ret, 2) # âœ… YENÄ°
                },
            }

            _PRICE_CACHE[fund_code] = new_data
            save_memory_to_disk()
            return new_data
        
        elif force_fetch and cached:
             # Fetch baÅŸarÄ±sÄ±z olduysa eski veriyi koru
             pass

    return cached if cached else {"nav": 0.0, "daily_return_pct": 0.0}

# ============================================================
# 4. MARKET DATA (BIST / USD) â€“ 15 DK
# ============================================================

def update_market_data():
    """BIST ve USD gÃ¼nceller"""
    items = []
    tickers = {"USDTRY": "USDTRY=X", "BIST100": "XU100.IS", "BIST30": "XU030.IS"}
    for c, s in tickers.items():
        try:
            t = yf.Ticker(s)
            info = t.fast_info
            p = info.last_price
            prev = info.previous_close
            pct = ((p - prev) / prev) * 100 if prev else 0.0
            items.append({"code": c, "value": round(p, 4), "change_pct": round(pct, 2)})
        except:
            items.append({"code": c, "value": 0.0, "change_pct": 0.0})

    # âœ… PATCH 2: Atomik yazma
    try:
        _atomic_write_json(MARKET_CACHE_PATH, {"asof": now_str(), "items": items})
        print(f"ğŸ”„ Market Updated: {now_str()}")
    except Exception as e:
        print(f"âŒ Market write error: {e}")
    return items

def _get_market_change_pct(code: str) -> float:
    """AI tahmin iÃ§in market yÃ¼zdesini okur (TEFAS deÄŸil)"""
    try:
        if os.path.exists(MARKET_CACHE_PATH):
            with open(MARKET_CACHE_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
            for it in data.get("items", []):
                if it.get("code") == code:
                    return float(it.get("change_pct", 0.0) or 0.0)
    except:
        pass
    return 0.0

# ============================================================
# 5. AI TAHMÄ°N (TEFAS YOK) â€“ 5 SN
# ============================================================

def get_ai_prediction_live(fund_code: str, daily_real: float) -> Dict[str, Any]:

    # ===============================
    # â° PÄ°YASA AÃ‡IK / KAPALI KONTROLÃœ
    # ===============================
    try:
        now_tr = datetime.now(ZoneInfo("Europe/Istanbul"))
    except:
        now_tr = datetime.now()

    # BIST: 09:30 â€“ 18:10 arasÄ± aÃ§Ä±k kabul edelim
    market_open = (
        (now_tr.hour > 9 or (now_tr.hour == 9 and now_tr.minute >= 30)) and
        (now_tr.hour < 18 or (now_tr.hour == 18 and now_tr.minute <= 10))
    )

    """
    ğŸ”’ Direction kilidi
    ğŸŒŠ YumuÅŸak jitter
    ğŸ§  Premium AI anchor
    TEFAS'a DOKUNMAZ
    """
    fund_code = fund_code.upper()
    now_ts = time.time()

    with _AI_LOCK:
        cached = _AI_CACHE.get(fund_code)
        
        # EÄŸer cached veri varsa ve "predicted_return_pct" yoksa (eski cache), yenile
        if cached and "predicted_return_pct" not in cached:
             cached = None

        # â›” PÄ°YASA KAPALIYSA â†’ CANLI AI KÄ°LÄ°TLENÄ°R
        if not market_open and cached:
            return cached

        # Market aÃ§Ä±ksa cache'i kÄ±salt
        try:
            now_tr = datetime.now(ZoneInfo("Europe/Istanbul"))
        except:
            now_tr = datetime.now()
        ttl = 1 if market_open else 3600  # KapalÄ±yken 1 saat kilit


        if cached and (now_ts - cached["_ts"]) < ttl:
            return cached

        # ===============================
        # MARKET VERÄ°LERÄ°
        # ===============================
        bist = _get_market_change_pct("BIST100")
        usd = _get_market_change_pct("USDTRY")

        # ===============================
        # ğŸ§  PREMIUM AI ANCHOR (TEK SATIR MANTIÄI)
        # ===============================
        master = _get_master_map_cached()
        rec = master.get(fund_code, {})
        fund_name = rec.get("name", "")
        fund_type = rec.get("type", "")

        premium = premium_build_prediction(
            fund_code=fund_code,
            fund_name=fund_name,
            fund_type_from_master=fund_type,
            daily_real_pct=daily_real,
            bist_change_pct=float(bist or 0.0),
            usd_change_pct=float(usd or 0.0),
            market_asof=now_str(),
        )
        premium_base = float(premium.get("predicted_return_pct", 0.0))

        # ===============================
        # ğŸŒŠ SOFT JITTER (Ã‡OK KÃœÃ‡ÃœK)
        # ===============================
        # deterministik (random yok)
        jitter = math.sin(now_ts / 60.0) * 0.03  # max Â±0.03

        # ===============================
        # GÃœN Ä°Ã‡Ä° DRIFT (KAPANIÅA SIFIRLANIR)
        # ===============================
        try:
            dt = datetime.now(ZoneInfo("Europe/Istanbul"))
        except:
            dt = datetime.now()
        minutes = dt.hour * 60 + dt.minute
        session_pos = max(0.0, min(1.0, (minutes - 570) / (1090 - 570)))
        drift = 0.12 * (1.0 - session_pos)

        # ===============================
        # ğŸ¯ FÄ°NAL TAHMÄ°N (AÄIRLIKLI)
        # ===============================
        # EÄŸer cached veride hisse bazlÄ± tahmin varsa (estimated_return), onu da kat
        fund_data = _PRICE_CACHE.get(fund_code, {})
        holdings_impact = 0.0
        if "ai_prediction" in fund_data:
             holdings_impact = fund_data["ai_prediction"].get("estimated_return", 0.0)

        # FormÃ¼l: Premium Base %50 + Holdings %40 + Daily %10
        predicted = (
            premium_base * 0.50 +
            holdings_impact * 0.40 +
            daily_real * 0.10 +
            drift * 0.05 +
            jitter
        )
        predicted = round(predicted, 2)

        # ===============================
        # ğŸ”’ DIRECTION LOCK
        # ===============================
        prev = _AI_DIRECTION_LOCK.get(fund_code)

        raw_direction = (
            "POZÄ°TÄ°F" if predicted > 0
            else "NEGATÄ°F" if predicted < 0
            else "NÃ–TR"
        )

        direction = raw_direction

        if prev:
            # yÃ¶n deÄŸiÅŸimi iÃ§in eÅŸik
            if raw_direction != prev["direction"]:
                # kÃ¼Ã§Ã¼k deÄŸiÅŸimde yÃ¶nÃ¼ KORU
                if abs(predicted) < 0.25:
                    direction = prev["direction"]
                else:
                    # yÃ¶n deÄŸiÅŸti ama TS gÃ¼ncelle
                    _AI_DIRECTION_LOCK[fund_code] = {
                        "direction": raw_direction,
                        "ts": now_ts,
                    }
            else:
                direction = prev["direction"]
        else:
            _AI_DIRECTION_LOCK[fund_code] = {
                "direction": raw_direction,
                "ts": now_ts,
            }

        confidence = int(min(95, max(10, 55 + abs(predicted) * 10)))

        out = {
            "predicted_return_pct": predicted,
            "direction": direction,
            "confidence_score": confidence,
            "asof": now_str(),
            "_ts": now_ts,
        }

        _AI_CACHE[fund_code] = out
        return out

# ============================================================
# 6. OTOMATÄ°K ZAMANLAYICI (MARKET DATA Ä°Ã‡Ä°N)
# ============================================================

def auto_market_loop():
    """Server aÃ§Ä±k olduÄŸu sÃ¼rece her 15 dakikada bir Ã§alÄ±ÅŸÄ±r"""
    while True:
        update_market_data()
        time.sleep(900)  # 15 dakika bekle

# ============================================================
# 6.5 âœ… PREMIUM AI SUMMARY (TIP Ã–ZET + TOP FONLAR)
# ============================================================

def _safe_float(v: Any, default: float = 0.0) -> float:
    try:
        if v is None:
            return default
        if isinstance(v, (int, float)):
            return float(v)
        s = str(v).strip().replace(",", ".").replace("%", "")
        return float(s) if s else default
    except:
        return default

def _build_predictions_summary(scope: str = "portfolio") -> Dict[str, Any]:
    """
    scope:
      - "portfolio": sadece portfÃ¶ydeki fonlar
      - "all": funds_master iÃ§indeki tÃ¼m fonlar
    """
    # market snapshot (premium_ai yardÄ±mcÄ±larÄ± ile)
    snap = read_market_snapshot(MARKET_CACHE_PATH)
    bist = market_change_pct(snap, "BIST100")
    usd = market_change_pct(snap, "USDTRY")
    market_asof = str(snap.get("asof") or "")

    master = _get_master_map_cached()

    # universe seÃ§imi
    codes: List[str] = []

    if scope == "all":
        codes = list(master.keys())
    else:
        # portfolio
        if os.path.exists(PORTFOLIO_PATH):
            try:
                with open(PORTFOLIO_PATH, "r", encoding="utf-8") as f:
                    raw = json.load(f)
                for pos in raw.get("positions", []):
                    c = str(pos.get("code") or "").upper().strip()
                    if c:
                        codes.append(c)
            except:
                codes = []

    # compute predictions
    items: List[Dict[str, Any]] = []
    by_type_acc: Dict[str, Dict[str, float]] = {}  # type -> {sum, cnt}

    for code in codes:
        rec = master.get(code, {}) if isinstance(master, dict) else {}
        fund_name = str(rec.get("name") or "")
        fund_type = str(rec.get("type") or "")

        # ğŸ“Œ RAM cache yoksa Disk cache'ten oku
        info = _PRICE_CACHE.get(code)
        
        if not info:
            if os.path.exists(LIVE_PRICES_PATH):
                try:
                    with open(LIVE_PRICES_PATH, "r", encoding="utf-8") as f:
                        disk_raw = json.load(f)
                    disk_data = disk_raw.get("data", {})
                    info = disk_data.get(code, {})
                except:
                    info = {}

        daily_real = _safe_float(info.get("daily_return_pct") if info else 0.0, 0.0)

        out = premium_build_prediction(
            fund_code=code,
            fund_name=fund_name,
            fund_type_from_master=fund_type,
            daily_real_pct=daily_real,
            bist_change_pct=float(bist or 0.0),
            usd_change_pct=float(usd or 0.0),
            market_asof=market_asof,
        )

        pred = _safe_float(out.get("predicted_return_pct"), 0.0)
        conf = int(_safe_float(out.get("confidence_score"), 50))
        direction = str(out.get("direction") or "NOTR")
        typ = str(out.get("meta", {}).get("fund_type") or fund_type or "DIGER")

        items.append({
            "code": code,
            "name": fund_name,
            "type": typ,
            "predicted_return_pct": round(pred, 2),
            "confidence_score": conf,
            "direction": direction,
        })

        acc = by_type_acc.get(typ)
        if not acc:
            by_type_acc[typ] = {"sum": pred, "cnt": 1.0}
        else:
            acc["sum"] += pred
            acc["cnt"] += 1.0

    # by_type averages
    by_type = []
    for t, acc in by_type_acc.items():
        cnt = int(acc["cnt"])
        avg = (acc["sum"] / acc["cnt"]) if acc["cnt"] else 0.0
        by_type.append({
            "type": t,
            "avg_pct": round(avg, 2),
            "count": cnt,
        })

    # sort by avg desc (kurumsal gÃ¶rÃ¼nÃ¼m)
    by_type.sort(key=lambda x: x.get("avg_pct", 0.0), reverse=True)

    # top funds: pred desc, conf >= 65
    top_funds = [x for x in items if int(x.get("confidence_score", 0)) >= 65]
    top_funds.sort(key=lambda x: (x.get("predicted_return_pct", 0.0), x.get("confidence_score", 0)), reverse=True)
    
    # âœ… FIX 3: Fallback mekanizmasÄ± (Liste asla boÅŸ dÃ¶nmesin)
    if not top_funds:
        items.sort(key=lambda x: (x.get("predicted_return_pct", 0.0), x.get("confidence_score", 0)), reverse=True)
        top_funds = items[:8]
    else:
        top_funds = top_funds[:8]

    return {
        "status": "success",
        "asof": now_str(),
        "scope": scope,
        "market": {
            "asof": market_asof,
            "bist_change_pct": round(float(bist or 0.0), 2),
            "usd_change_pct": round(float(usd or 0.0), 2),
        },
        "by_type": by_type,
        "top_funds": top_funds,
        "count": len(items),
    }

# ============================================================
# 7. YENÄ°: OTOMATÄ°K GÃœNCELLEME SÄ°STEMÄ°
# ============================================================

def update_newly_added_funds(fund_codes: List[str]):
    """
    Yeni eklenen fonlarÄ± hemen gÃ¼nceller
    """
    if not fund_codes:
        return
        
    print(f"ğŸš€ Yeni eklenen fonlar gÃ¼ncelleniyor: {', '.join(fund_codes)}")
    
    for i, code in enumerate(fund_codes, 1):
        print(f"ğŸ“ˆ [{i}/{len(fund_codes)}] GÃ¼ncelleniyor: {code}")
        try:
            result = get_fund_data_safe(code)
            if result and result.get("nav", 0) > 0:
                print(f"âœ… {code} baÅŸarÄ±yla gÃ¼ncellendi - Fiyat: {result['nav']:.4f}")
            else:
                print(f"âŒ {code} gÃ¼ncellenemedi - Veri alÄ±namadÄ±")
        except Exception as e:
            print(f"ğŸ’¥ {code} gÃ¼ncelleme hatasÄ±: {str(e)}")
        
        time.sleep(0.4)  # Ban korumasÄ±
    
    print(f"ğŸ¯ TÃ¼m yeni fonlar iÅŸlendi: {len(fund_codes)} adet")

# âœ… GÃœNCELLENDÄ°: "Any" yerine tÃ¼m portfÃ¶yÃ¼n gÃ¼ncel olup olmadÄ±ÄŸÄ±nÄ± kontrol eder ve timezone dÃ¼zeltmesi
def maybe_update_portfolio_funds():
    """
    09:30 sonrasÄ± portfÃ¶y fonlarÄ±nÄ± GÃœNDE 1 KEZ (effective_day bazlÄ±) tamamlar.
    """
    # EÄŸer server restart olmuÅŸsa (RAM cache boÅŸsa) gÃ¼nlÃ¼k kilidi resetle
    if not _PRICE_CACHE:
        _save_portfolio_update_day("")

    try:
        now = datetime.now(ZoneInfo("Europe/Istanbul"))
    except:
        now = datetime.now()
    if now.hour < 9 or (now.hour == 9 and now.minute < 30):
        return

    today = now.strftime("%Y-%m-%d")
    effective_day = tefas_effective_date()
    run_day = effective_day  # âœ… State anahtarÄ± bu olmalÄ±

    with _PORTFOLIO_UPDATE_LOCK:
        # PortfÃ¶y yoksa state yazÄ±p Ã§Ä±k
        if not os.path.exists(PORTFOLIO_PATH):
            _save_portfolio_update_day(run_day)
            return

        # PortfÃ¶y kodlarÄ±nÄ± oku
        try:
            with open(PORTFOLIO_PATH, "r", encoding="utf-8") as f:
                raw = json.load(f)
            codes = [
                (p.get("code") or "").upper().strip()
                for p in raw.get("positions", [])
                if p.get("code")
            ]
        except Exception as e:
            print(f"âŒ PortfÃ¶y okuma hata: {e}")
            return

        # Eksikleri bul (RAM + disk Ã¼zerinden)
        missing = _missing_codes_for_day(codes, effective_day)
        last_day = _load_portfolio_update_day()

        # âœ… SADECE: run_day state yazÄ±lmÄ±ÅŸ VE portfÃ¶yde eksik yoksa erken Ã§Ä±k
        if last_day == run_day and not missing:
            return

        # Eksik yoksa state'i dÃ¼zelt ve Ã§Ä±k
        if not missing:
            _save_portfolio_update_day(run_day)
            return

        print(f"ğŸ”„ PortfÃ¶y auto-update: {len(missing)}/{len(codes)} fon eksik, gÃ¼ncellenecek. effective_day={effective_day}")

        # Sadece eksikleri gÃ¼ncelle
        for code in missing:
            try:
                get_fund_data_safe(code)
            except Exception as e:
                print(f"âŒ PortfÃ¶y update hata ({code}): {e}")
            time.sleep(0.4)  # ğŸ”’ BAN KORUMASI

        # GÃ¼n bitti (portfÃ¶y tamamlandÄ± mÄ± kontrol et) â†’ state yaz
        missing2 = _missing_codes_for_day(codes, effective_day)
        if not missing2:
            _save_portfolio_update_day(run_day)
            print(f"âœ… PortfÃ¶y fonlarÄ± tamamlandÄ± ({run_day})")
        else:
            print(f"âš ï¸ PortfÃ¶y fonlarÄ± kÄ±smi kaldÄ±: {len(missing2)} fon hÃ¢lÃ¢ eksik; sonraki istekte tekrar denenecek.")

# âœ… GÃœNCELLENDÄ°: "Any" yerine tÃ¼m canlÄ± listenin gÃ¼ncel olup olmadÄ±ÄŸÄ±nÄ± kontrol eder ve timezone dÃ¼zeltmesi
def maybe_update_live_list_funds():
    """
    09:30 sonrasÄ± canlÄ± listedeki fonlarÄ± GÃœNDE 1 KEZ (effective_day bazlÄ±) tamamlar.
    """
    # EÄŸer server restart olmuÅŸsa (RAM cache boÅŸsa) gÃ¼nlÃ¼k kilidi resetle
    if not _PRICE_CACHE:
        _save_live_list_update_day("")

    try:
        now = datetime.now(ZoneInfo("Europe/Istanbul"))
    except:
        now = datetime.now()
    if now.hour < 9 or (now.hour == 9 and now.minute < 30):
        return

    today = now.strftime("%Y-%m-%d")
    effective_day = tefas_effective_date()
    run_day = effective_day  # âœ… State anahtarÄ± bu olmalÄ±

    with _LIVE_LIST_UPDATE_LOCK:
        # Liste yoksa state yazÄ±p Ã§Ä±k
        if not os.path.exists(LIVE_LIST_PATH):
            _save_live_list_update_day(run_day)
            return

        # Liste kodlarÄ±nÄ± oku
        try:
            with open(LIVE_LIST_PATH, "r", encoding="utf-8") as f:
                raw = json.load(f)
            codes = [
                (item.get("code") or "").upper().strip()
                for item in raw.get("items", [])
                if item.get("code")
            ]
        except Exception as e:
            print(f"âŒ CanlÄ± liste okuma hata: {e}")
            return

        # Eksikleri bul
        missing = _missing_codes_for_day(codes, effective_day)
        last_day = _load_live_list_update_day()

        # âœ… SADECE: run_day state yazÄ±lmÄ±ÅŸ VE listede eksik yoksa erken Ã§Ä±k
        if last_day == run_day and not missing:
            return

        # Eksik yoksa state'i dÃ¼zelt ve Ã§Ä±k
        if not missing:
            _save_live_list_update_day(run_day)
            return

        print(f"ğŸ”„ CanlÄ± liste auto-update: {len(missing)}/{len(codes)} fon eksik, gÃ¼ncellenecek. effective_day={effective_day}")

        # Sadece eksikleri gÃ¼ncelle
        for code in missing:
            try:
                get_fund_data_safe(code)
            except Exception as e:
                print(f"âŒ CanlÄ± liste update hata ({code}): {e}")
            time.sleep(0.4)  # Ban korumasÄ±

        # GÃ¼n bitti mi kontrol et â†’ state yaz
        missing2 = _missing_codes_for_day(codes, effective_day)
        if not missing2:
            _save_live_list_update_day(run_day)
            print(f"âœ… CanlÄ± liste fonlarÄ± tamamlandÄ± ({run_day})")
        else:
            print(f"âš ï¸ CanlÄ± liste fonlarÄ± kÄ±smi kaldÄ±: {len(missing2)} fon hÃ¢lÃ¢ eksik; sonraki istekte tekrar denenecek.")

# ============================================================
# 8. API ENDPOINTS
# ============================================================

@router.get("/admin/refresh")
def api_refresh():
    m = update_market_data()
    return {"status": "success", "message": "Piyasa GÃ¼ncellendi.", "market": m}

@router.get("/market")
def api_market():
    data = {"items": []}
    if os.path.exists(MARKET_CACHE_PATH):
        try:
            with open(MARKET_CACHE_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
        except:
            pass
    return {"status": "success", "data": {"market": data}}

@router.get("/predictions/summary")
def api_predictions_summary(scope: str = "portfolio"):
    """
    âœ… Yeni endpoint:
      GET /funds/predictions/summary?scope=portfolio
      GET /funds/predictions/summary?scope=all

    DÃ¶ner:
      by_type: tip bazlÄ± ortalamalar
      top_funds: gÃ¼Ã§lÃ¼ fonlar listesi
    """
    global _PRED_SUMMARY_CACHE, _PRED_SUMMARY_TS
    scope = (scope or "portfolio").strip().lower()
    if scope not in ("portfolio", "all"):
        scope = "portfolio"

    # âœ… PATCH 3.4: 15 sn cache (scope bazlÄ±)
    with _PRED_SUMMARY_LOCK:
        ts = time.time()
        cached = _PRED_SUMMARY_CACHE.get(scope)
        last_ts = _PRED_SUMMARY_TS.get(scope, 0.0)
        if cached and (ts - last_ts) < _PRED_SUMMARY_TTL_SEC:
            return cached

    data = _build_predictions_summary(scope=scope)

    # âœ… PATCH 3.6: TS scope bazlÄ± update
    with _PRED_SUMMARY_LOCK:
        _PRED_SUMMARY_CACHE[scope] = data
        _PRED_SUMMARY_TS[scope] = time.time()

    return data

@router.get("/portfolio")
def api_portfolio():
    # ğŸ”¥ 09:30 sonrasÄ± otomatik portfÃ¶y gÃ¼ncelleme
    maybe_update_portfolio_funds()

    if os.path.exists(PORTFOLIO_PATH):
        try:
            with open(PORTFOLIO_PATH, "r", encoding="utf-8") as f:
                raw_portfolio = json.load(f)
        except:
            raw_portfolio = {"positions": []}
    else:
        raw_portfolio = {"positions": []}

    result_list = []
    for pos in raw_portfolio.get("positions", []):
        code = (pos.get("code") or "").upper().strip()
        if not code:
            continue
        qty = float(pos.get("quantity", 0) or 0)

        # TEFAÅ cacheli gerÃ§ek veri (gÃ¼nde 1 kere)
        info = get_fund_data_safe(code)
        daily_real = float(info.get("daily_return_pct", 0.0) or 0.0)

        # AI tahmin (sadece yÃ¶n iÃ§in)
        ai = get_ai_prediction_live(code, daily_real)

        # ğŸ¯ Ã‡Ã–ZÃœM: Mobil app'in beklediÄŸi alanlarÄ± gerÃ§ek TEFAÅ verilerine baÄŸla
        result_list.append({
            "code": code,
            "quantity": qty,
            "nav": info.get("nav", 0.0),
            "daily_return_pct": daily_real,                    # âœ… TEFAÅ gerÃ§ek %
            
            # ğŸ¯ Ã‡Ã–ZÃœM: Mobil'in predicted_return_pct alanÄ±na AI TAHMÄ°NÄ° koy (Fix 2)
            "predicted_return_pct": ai.get("predicted_return_pct", daily_real), 
            "confidence_score": ai.get("confidence_score", 50),
            "direction": ai.get("direction", "NÃ–TR"),
            
            "value": qty * float(info.get("nav", 0.0) or 0.0),

            # ESKÄ° alanÄ± koru (mevcut sistemle uyumlu)
            "prediction": info.get("ai_prediction", {}),
        })

    return {"status": "success", "data": result_list}

@router.post("/portfolio/set")
def api_pset(payload: Dict[str, Any]):
    """
    payload: {"positions":[{"code":"AFT","quantity":10}, ...]}
    
    YENÄ°: Fon eklendiÄŸinde otomatik gÃ¼ncelleme
    """
    try:
        positions = payload.get("positions", [])
        
        # âœ… YENÄ°: Ã–nceki fon kodlarÄ±nÄ± oku
        previous_codes = _get_portfolio_codes()
        
        # PortfÃ¶yÃ¼ kaydet
        with open(PORTFOLIO_PATH, "w", encoding="utf-8") as f:
            json.dump({"asof": now_str(), "positions": positions}, f, ensure_ascii=False, indent=2)
        
        # âœ… YENÄ°: Yeni eklenen fonlarÄ± tespit et ve gÃ¼ncelle
        current_codes = [str(pos.get("code") or "").upper().strip() for pos in positions if pos.get("code")]
        new_funds = _get_newly_added_funds(previous_codes, current_codes)
        
        if new_funds:
            print(f"ğŸ†• Yeni fonlar tespit edildi: {', '.join(new_funds)}")
            update_newly_added_funds(new_funds)
        
    except:
        pass
    return {"status": "success"}

@router.get("/list")
def api_list():
    if os.path.exists(FUNDS_MASTER_PATH):
        try:
            with open(FUNDS_MASTER_PATH, "r", encoding="utf-8") as f:
                master = json.load(f)
        except:
            master = []
    else:
        master = []
    return {"status": "success", "data": {"items": master}}

@router.get("/live-list")
def api_live_list():
    """
    âœ… YENÄ°: CanlÄ± liste endpoint'i
    09:30 sonrasÄ± otomatik gÃ¼ncelleme yapar
    """
    # 09:30 sonrasÄ± otomatik canlÄ± liste gÃ¼ncelleme
    maybe_update_live_list_funds()
    
    if os.path.exists(LIVE_LIST_PATH):
        try:
            with open(LIVE_LIST_PATH, "r", encoding="utf-8") as f:
                raw_list = json.load(f)
        except:
            raw_list = {"items": []}
    else:
        raw_list = {"items": []}

    result_list = []
    for item in raw_list.get("items", []):
        code = (item.get("code") or "").upper().strip()
        if not code:
            continue

        # TEFAÅ cacheli gerÃ§ek veri (gÃ¼nde 1 kere)
        info = get_fund_data_safe(code)
        daily_real = float(info.get("daily_return_pct", 0.0) or 0.0)

        # AI tahmin
        ai = get_ai_prediction_live(code, daily_real)

        result_list.append({
            "code": code,
            "name": item.get("name", ""),
            "nav": info.get("nav", 0.0),
            "daily_return_pct": daily_real,
            "predicted_return_pct": ai.get("predicted_return_pct", daily_real),
            "confidence_score": ai.get("confidence_score", 50),
            "direction": ai.get("direction", "NÃ–TR"),
            "type": item.get("type", ""),
        })

    return {"status": "success", "data": result_list}

@router.post("/live-list/set")
def api_live_list_set(payload: Dict[str, Any]):
    """
    payload: {"items":[{"code":"AFT","name":"..."}, ...]}
    
    YENÄ°: CanlÄ± listeye fon eklendiÄŸinde otomatik gÃ¼ncelleme
    """
    try:
        items = payload.get("items", [])
        
        # âœ… YENÄ°: Ã–nceki fon kodlarÄ±nÄ± oku
        previous_codes = _get_live_list_codes()
        
        # CanlÄ± listeyi kaydet
        with open(LIVE_LIST_PATH, "w", encoding="utf-8") as f:
            json.dump({"asof": now_str(), "items": items}, f, ensure_ascii=False, indent=2)
        
        # âœ… YENÄ°: Yeni eklenen fonlarÄ± tespit et ve gÃ¼ncelle
        current_codes = [str(item.get("code") or "").upper().strip() for item in items if item.get("code")]
        new_funds = _get_newly_added_funds(previous_codes, current_codes)
        
        if new_funds:
            print(f"ğŸ†• CanlÄ± listeye yeni fonlar eklendi: {', '.join(new_funds)}")
            update_newly_added_funds(new_funds)
        
    except:
        pass
    return {"status": "success"}

@router.get("/detail/{code}")
def api_detail(code: str):
    # Detayda cacheli hÄ±zlÄ± dÃ¶n (gÃ¼nde 1 TEFAS)
    info = get_fund_data_safe(code)
    if info.get("nav", 0) > 0:
        daily_real = float(info.get("daily_return_pct", 0.0) or 0.0)
        ai = get_ai_prediction_live(code.upper(), daily_real)
        
        # EÄŸer Fintables'tan gelen detaylÄ± AI skoru varsa (hisse bazlÄ±), onu da ekle
        predicted_return = ai.get("predicted_return_pct", daily_real)
        if "ai_prediction" in info and "estimated_return" in info["ai_prediction"]:
             # Cache'teki hisse bazlÄ± skoru kullanabiliriz, ama live market data daha taze
             # O yÃ¼zden get_ai_prediction_live fonksiyonu zaten bunu birleÅŸtiriyor.
             pass

        return {
            "status": "success",
            "data": {
                **info,
                # ğŸ¯ Ã‡Ã–ZÃœM: Mobil kolay kullansÄ±n diye dÃ¼z alanlar (Fix 2)
                "predicted_return_pct": predicted_return,
                "confidence_score": ai.get("confidence_score", 50),
                "direction": ai.get("direction", "NÃ–TR"),
            }
        }
    return {"status": "error", "message": "Veri yok"}

# @router.get("/admin/refresh-tefas")
# def admin_refresh_tefas():
#     """
#     TEFAS toplu batch scrape.
#     Runtime API'yi etkilemez.
#     """
#     result = run_batch_scrape()
#     return {
#         "status": "success",
#         "message": "TEFAS batch scrape tamamlandÄ±",
#         "result": result
#     }

# âœ… EKLENDÄ°: Server aÃ§Ä±lÄ±ÅŸÄ±nda bootstrap gÃ¼ncellemesi
def _startup_bootstrap_updates():
    # Uvicorn import sÄ±rasÄ±nda hemen saldÄ±rmasÄ±n, biraz bekle
    time.sleep(2)

    # Server 09:30 sonrasÄ± aÃ§Ä±ldÄ±ysa anÄ±nda dene; deÄŸilse endpoint zaten tetikler.
    try:
        maybe_update_portfolio_funds()
    except Exception as e:
        print(f"âŒ Startup portfolio bootstrap hata: {e}")

    try:
        maybe_update_live_list_funds()
    except Exception as e:
        print(f"âŒ Startup live-list bootstrap hata: {e}")

# âœ… PATCH 4.2: Threadleri tek sefer baÅŸlat (reload-safe)
def _start_background_jobs_once():
    """Uvicorn reload / Ã§oklu import durumunda thread'leri tek sefer baÅŸlat."""
    global _BG_STARTED
    with _BG_LOCK:
        if _BG_STARTED:
            return
        _BG_STARTED = True

        # 1) Cache'i RAM'e yÃ¼kle
        load_cache_to_memory()

        # 2) Market loop thread
        t_market = threading.Thread(target=auto_market_loop, daemon=True)
        t_market.start()

        # 3) Startup bootstrap thread
        t_boot = threading.Thread(target=_startup_bootstrap_updates, daemon=True)
        t_boot.start()

# âœ… Import olur olmaz Ã§alÄ±ÅŸtÄ±r (ama tek sefer)
_start_background_jobs_once()
