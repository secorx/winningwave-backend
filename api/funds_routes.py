# api/funds_routes.py
# FINTABLES KALÄ°TESÄ°NDE - KAP VAKUM MODU - %100 FIX - FULL FILE (TEK SATIR EKSÄ°K YOK)

from __future__ import annotations

import os
import json
import time
import threading
import math
import re
import requests
import urllib3
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional
from bs4 import BeautifulSoup  # HTML Parsing iÃ§in

# ğŸ”¥ KRÄ°TÄ°K IMPORT: YFINANCE EKLENDÄ°
import yfinance as yf

try:
    from zoneinfo import ZoneInfo
except Exception:
    ZoneInfo = None

from fastapi import APIRouter

# âœ… EKLENDÄ°: Premium AI araÃ§larÄ± (summary iÃ§in)
# EÄŸer bu dosya yoksa hata vermemesi iÃ§in try-except bloÄŸu eklendi
try:
    from api.premium_ai import (
        build_premium_prediction as premium_build_prediction,
        load_funds_master_map,
        read_market_snapshot,
        market_change_pct,
    )
    PREMIUM_AI_AVAILABLE = True
except ImportError:
    PREMIUM_AI_AVAILABLE = False
    # Dummy fonksiyonlar (Import hatasÄ± durumunda kodun Ã§Ã¶kmemesi iÃ§in)
    def premium_build_prediction(*args, **kwargs): return {}
    def load_funds_master_map(*args, **kwargs): return {}
    def read_market_snapshot(*args, **kwargs): return {}
    def market_change_pct(*args, **kwargs): return 0.0


# ============================================================
# CACHE BASE DIR (LOCAL vs RENDER SAFE)
# ============================================================

def _detect_project_root() -> str:
    """
    funds.py hangi klasÃ¶rde olursa olsun proje root'unu bulmaya Ã§alÄ±ÅŸÄ±r.
    Ã–ncelik: iÃ§inde funds_cache veya data klasÃ¶rÃ¼ olan Ã¼st dizin.
    """
    here = os.path.abspath(os.path.dirname(__file__))
    candidates = [
        os.path.abspath(os.path.join(here, "..")),        # 1 Ã¼st
        os.path.abspath(os.path.join(here, "..", "..")),  # 2 Ã¼st
        os.path.abspath(os.path.join(here, "..", "..", "..")),  # 3 Ã¼st
    ]
    for c in candidates:
        if os.path.isdir(os.path.join(c, "funds_cache")) or os.path.isdir(os.path.join(c, "data")):
            return c
    # fallback
    return candidates[0]

BASE_DIR = _detect_project_root()

CACHE_ROOT = os.getenv(
    "CACHE_ROOT",
    BASE_DIR  # local default
)

CACHE_DIR = os.path.join(CACHE_ROOT, "funds_cache")
os.makedirs(CACHE_DIR, exist_ok=True)

# âœ… DATA DIR (HER ZAMAN PROJE Ä°Ã‡Ä°NDE)
DATA_DIR = os.path.join(BASE_DIR, "data")
os.makedirs(DATA_DIR, exist_ok=True)


# SSL UyarÄ±larÄ±nÄ± Kapat
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

router = APIRouter(tags=["funds"])

# ============================================================
# 1. AYARLAR & GLOBAL HAFIZA
# ============================================================

FUNDS_MASTER_PATH = os.path.join(DATA_DIR, "funds_master.json")
LIVE_PRICES_PATH = os.path.join(CACHE_DIR, "live_prices.json")
# âœ… HÄ°SSE FÄ°YATLARI Ä°Ã‡Ä°N (AI HESAPLAMASINDA KULLANILACAK)
STOCKS_LIVE_PRICES_PATH = os.path.join(DATA_DIR, "live_prices.json") 

PORTFOLIO_PATH = os.path.join(CACHE_DIR, "portfolio.json")
MARKET_CACHE_PATH = os.path.join(CACHE_DIR, "market_cache.json")
PREDICTION_CACHE_PATH = os.path.join(CACHE_DIR, "prediction_cache.json")

# âœ… YENÄ°: CanlÄ± liste dosyasÄ±
LIVE_LIST_PATH = os.path.join(CACHE_DIR, "live_list.json")

# âœ… YENÄ°: PortfÃ¶y gÃ¼ncelleme durumu iÃ§in dosya yolu
PORTFOLIO_UPDATE_STATE_PATH = os.path.join(CACHE_DIR, "portfolio_update_state.json")
# âœ… YENÄ°: CanlÄ± liste gÃ¼ncelleme durumu iÃ§in dosya yolu
LIVE_LIST_UPDATE_STATE_PATH = os.path.join(CACHE_DIR, "live_list_update_state.json")

# âœ… YENÄ°: Fetch Tracking Path (Tekrar Ã§ekimi Ã¶nlemek iÃ§in)
FETCH_TRACKING_PATH = os.path.join(CACHE_DIR, "fetch_tracking.json")

# GLOBAL DEÄÄ°ÅKENLER & LOCKLAR
_PRICE_CACHE: Dict[str, Dict] = {}
_TEFAS_LOCK = threading.Lock()
_AI_CACHE: Dict[str, Dict[str, Any]] = {}
_AI_LOCK = threading.Lock()
_AI_DIRECTION_LOCK: Dict[str, Dict[str, Any]] = {}
_MASTER_MAP: Dict[str, Dict[str, Any]] = {}
_MASTER_MAP_TS: float = 0.0
_MASTER_LOCK = threading.Lock()
_MASTER_TTL_SEC = 3600
_PRED_SUMMARY_CACHE: Dict[str, Any] = {}
_PRED_SUMMARY_TS: Dict[str, float] = {}
_PRED_SUMMARY_LOCK = threading.Lock()
_PRED_SUMMARY_TTL_SEC = 15
_PORTFOLIO_UPDATE_LOCK = threading.Lock()
_LIVE_LIST_UPDATE_LOCK = threading.Lock()
_BG_STARTED = False
_BG_LOCK = threading.Lock()

# ============================================================
# 2. YARDIMCI FONKSÄ°YONLAR
# ============================================================

# âœ… GÃœNCELLENDÄ°: now_str() Istanbul saatine gÃ¶re
def now_str() -> str:
    try:
        if ZoneInfo:
            return datetime.now(ZoneInfo("Europe/Istanbul")).strftime("%Y-%m-%d %H:%M:%S")
    except:
        pass
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


# âœ… GÃœNCELLENDÄ°: today_str() Istanbul saatine gÃ¶re
def today_str() -> str:
    try:
        if ZoneInfo:
            return datetime.now(ZoneInfo("Europe/Istanbul")).strftime("%Y-%m-%d")
    except:
        pass
    return datetime.now().strftime("%Y-%m-%d")

# âœ… YARDIMCI: Ã–nceki iÅŸ gÃ¼nÃ¼nÃ¼ bul
def _prev_business_day(d):
    d = d - timedelta(days=1)
    while d.weekday() >= 5:  # 5=Sat, 6=Sun
        d = d - timedelta(days=1)
    return d

# âœ… DÃœZELTÄ°LDÄ°: TEFAS Effective Date (Haftasonu + 09:30 KuralÄ±)
def tefas_effective_date() -> str:
    try:
        now = datetime.now(ZoneInfo("Europe/Istanbul"))
    except:
        now = datetime.now()

    today = now.date()
    after_0930 = (now.hour > 9) or (now.hour == 9 and now.minute >= 30)

    if today.weekday() >= 5:
        # Hafta sonu: TEFAS hÃ¢lÃ¢ PerÅŸembe'yi verir (Cuma verisi â€œyayÄ±nlanmÄ±ÅŸâ€ sayÄ±lmaz)
        d = _prev_business_day(_prev_business_day(today))
    else:
        if after_0930:
            # 09:30 sonrasÄ±: dÃ¼nÃ¼n iÅŸ gÃ¼nÃ¼
            d = _prev_business_day(today)
        else:
            # 09:30 Ã¶ncesi: iki Ã¶nceki iÅŸ gÃ¼nÃ¼
            d = _prev_business_day(_prev_business_day(today))

    return d.strftime("%Y-%m-%d")

# âœ… YENÄ°: PortfÃ¶y gÃ¼ncelleme durumu iÃ§in dosya yolu
def _load_portfolio_update_day() -> Optional[str]:
    if os.path.exists(PORTFOLIO_UPDATE_STATE_PATH):
        try:
            with open(PORTFOLIO_UPDATE_STATE_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
                return data.get("last_day")
        except:
            pass
    return None

# âœ… YENÄ°: PortfÃ¶y gÃ¼ncelleme durumu diske yaz
def _save_portfolio_update_day(day: str):
    try:
        with open(PORTFOLIO_UPDATE_STATE_PATH, "w", encoding="utf-8") as f:
            json.dump({"last_day": day}, f, ensure_ascii=False)
    except:
        pass

# âœ… YENÄ°: CanlÄ± liste gÃ¼ncelleme durumu diskten oku (Optional ile uyumlu)
def _load_live_list_update_day() -> Optional[str]:
    if os.path.exists(LIVE_LIST_UPDATE_STATE_PATH):
        try:
            with open(LIVE_LIST_UPDATE_STATE_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
                return data.get("last_day")
        except:
            pass
    return None

# âœ… YENÄ°: CanlÄ± liste gÃ¼ncelleme durumu diske yaz
def _save_live_list_update_day(day: str):
    try:
        with open(LIVE_LIST_UPDATE_STATE_PATH, "w", encoding="utf-8") as f:
            json.dump({"last_day": day}, f, ensure_ascii=False)
    except:
        pass

# âœ… YENÄ°: FETCH TRACKING HELPER'LARI
def _load_fetch_tracking() -> Dict[str, str]:
    if os.path.exists(FETCH_TRACKING_PATH):
        try:
            with open(FETCH_TRACKING_PATH, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            pass
    return {}

def _save_fetch_tracking(data: Dict[str, str]):
    try:
        with open(FETCH_TRACKING_PATH, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except:
        pass

# âœ… GÃœNCELLENDÄ°: RAM CACHE Ä°Ã‡Ä°NDE GÃœNCEL VERÄ° KONTROLÃœ
def _is_code_fresh(code: str, effective_day: str) -> bool:
    code = code.upper().strip()

    def check_rec(r: Dict) -> bool:
        if not r or r.get("nav", 0) <= 0:
            return False
        rec_asof = str(r.get("asof_day") or "").strip()
        if rec_asof == effective_day:
            return True
        if not rec_asof and str(r.get("last_update", "")).startswith(effective_day):
            return True
        return False

    if check_rec(_PRICE_CACHE.get(code)):
        return True

    if os.path.exists(LIVE_PRICES_PATH):
        try:
            with open(LIVE_PRICES_PATH, "r", encoding="utf-8") as f:
                disk_raw = json.load(f)
            disk_data = disk_raw.get("data", {}) if isinstance(disk_raw, dict) else {}
            if check_rec(disk_data.get(code)):
                return True
        except:
            pass

    return False

def _missing_codes_for_day(codes: List[str], effective_day: str) -> List[str]:
    out = []
    for c in codes:
        c2 = (c or "").upper().strip()
        if c2 and not _is_code_fresh(c2, effective_day):
            out.append(c2)
    return out

# âœ… YENÄ°: CanlÄ± listeden fon kodlarÄ±nÄ± oku
def _get_live_list_codes() -> List[str]:
    codes = []
    if os.path.exists(LIVE_LIST_PATH):
        try:
            with open(LIVE_LIST_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
            for item in data.get("items", []):
                code = str(item.get("code") or "").upper().strip()
                if code:
                    codes.append(code)
        except:
            pass
    return codes

# âœ… YENÄ°: PortfÃ¶yden fon kodlarÄ±nÄ± oku
def _get_portfolio_codes() -> List[str]:
    codes = []
    if os.path.exists(PORTFOLIO_PATH):
        try:
            with open(PORTFOLIO_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
            for pos in data.get("positions", []):
                code = str(pos.get("code") or "").upper().strip()
                if code:
                    codes.append(code)
        except:
            pass
    return codes

# âœ… YENÄ°: Ä°lk defa eklenen fonlarÄ± tespit et
def _get_newly_added_funds(previous_codes: List[str], current_codes: List[str]) -> List[str]:
    prev_set = set(previous_codes)
    new_codes = [code for code in current_codes if code not in prev_set]
    return new_codes

# ğŸ“Œ DÃœZELTME 1: Unicode eksi iÅŸareti ve temizleme mantÄ±ÄŸÄ±
def _parse_turkish_float(text: str) -> float:
    try:
        s = str(text).strip()
        s = s.replace("âˆ’", "-")
        s = s.replace("%", "")
        # 1.234,56 -> 1234.56
        if "," in s and "." in s:
            s = s.replace(".", "").replace(",", ".")
        elif "," in s:
            s = s.replace(",", ".")
        s = re.sub(r"[^0-9.-]", "", s)
        return float(s)
    except:
        return 0.0

# âœ… DÃœZELTÄ°LDÄ°: load_cache_to_memory
def load_cache_to_memory():
    global _PRICE_CACHE
    if not os.path.exists(LIVE_PRICES_PATH):
        _PRICE_CACHE = {}
    else:
        try:
            with open(LIVE_PRICES_PATH, "r", encoding="utf-8") as f:
                raw = json.load(f)
            if isinstance(raw, dict) and "data" in raw:
                _PRICE_CACHE = raw["data"]
            else:
                _PRICE_CACHE = raw
            print(f"âœ… RAM cache yÃ¼klendi: {len(_PRICE_CACHE)} fon")
        except Exception as e:
            print(f"âŒ Cache yÃ¼klenedi: {e}")
            _PRICE_CACHE = {}

# âœ… ADIM 3: KAYIT FORMATI DÃœZELTÄ°LDÄ°
def save_memory_to_disk():
    try:
        tmp = LIVE_PRICES_PATH + ".tmp"
        with open(tmp, "w", encoding="utf-8") as f:
            json.dump(
                {"data": _PRICE_CACHE, "asof": now_str()},
                f,
                ensure_ascii=False,
                indent=2
            )
        os.replace(tmp, LIVE_PRICES_PATH)
    except Exception as e:
        print(f"âŒ save_memory_to_disk: {e}")

# âœ… PATCH 1.1: Atomik JSON yazma helper'Ä±
def _atomic_write_json(path: str, obj: Any):
    try:
        tmp = path + ".tmp"
        with open(tmp, "w", encoding="utf-8") as f:
            json.dump(obj, f, ensure_ascii=False, indent=2)
        os.replace(tmp, path)
    except Exception as e:
        print(f"âŒ _atomic_write_json({path}): {e}")

# âœ… EKLENDÄ°: master map'i cacheli oku
def _get_master_map_cached() -> Dict[str, Dict[str, Any]]:
    global _MASTER_MAP, _MASTER_MAP_TS
    if not PREMIUM_AI_AVAILABLE:
        return {}

    ts = time.time()
    if _MASTER_MAP and (ts - _MASTER_MAP_TS) < _MASTER_TTL_SEC:
        return _MASTER_MAP

    with _MASTER_LOCK:
        ts = time.time()
        if _MASTER_MAP and (ts - _MASTER_MAP_TS) < _MASTER_TTL_SEC:
            return _MASTER_MAP
        _MASTER_MAP = load_funds_master_map(FUNDS_MASTER_PATH)
        _MASTER_MAP_TS = ts
        return _MASTER_MAP

# ============================================================
# 3. VERÄ° Ã‡EKME MOTORU (TEFAS & KAP - Ä°Å YATIRIM)
# ============================================================

def _fetch_html_tefas(fund_code: str):
    print(f"ğŸŒ TEFAS HTML deniyorum: {fund_code}")
    url = f"https://www.tefas.gov.tr/FonAnaliz.aspx?FonKod={fund_code.upper()}"
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"}
    
    try:
        r = requests.get(url, headers=headers, timeout=10, verify=False)
        r.encoding = 'utf-8' # ENCODING FIX
        if r.status_code == 200:
            price, daily, yearly = 0.0, 0.0, 0.0
            
            m = re.search(r"Son Fiyat.*?<span>([\d,\.]+)</span>", r.text, re.DOTALL)
            if m: price = _parse_turkish_float(m.group(1))
            
            m = re.search(r"GÃ¼nlÃ¼k Getiri.*?<span>(.*?)</span>", r.text, re.DOTALL)
            if m: daily = _parse_turkish_float(m.group(1))
            
            m = re.search(r"Son 1 YÄ±l.*?<span>(.*?)</span>", r.text, re.DOTALL)
            if m: yearly = _parse_turkish_float(m.group(1))
            
            if price > 0:
                return {"price": price, "daily_pct": daily, "yearly_pct": yearly, "source": "HTML"}
    except Exception as e:
        print(f"âŒ TEFAS HTML Hata: {e}")
    return None

def _fetch_api_tefas(fund_code: str):
    """TEFAS API Yedek"""
    url = "https://www.tefas.gov.tr/api/DB/BindHistoryInfo"
    try:
        end = datetime.now()
        start = end - timedelta(days=7)
        payload = {
            "fontip": "YAT",
            "fonkod": fund_code.upper(),
            "bastarih": start.strftime("%d.%m.%Y"),
            "bittarih": end.strftime("%d.%m.%Y"),
        }
        r = requests.post(url, data=payload, timeout=10, verify=False)
        if r.status_code == 200:
            data = r.json().get("data", [])
            if data:
                valid = []
                for i in data:
                    ts = i.get("TARIH", 0)
                    if ts: valid.append(i)
                
                if valid:
                    valid.sort(key=lambda x: x.get("TARIH", 0), reverse=True)
                    last = valid[0] 
                    price = _parse_turkish_float(last.get("FIYAT", 0))
                    if price > 0:
                        return {"price": price, "daily_pct": None, "yearly_pct": 0.0, "source": "API", "asof_day": datetime.fromtimestamp(last.get("TARIH", 0)/1000).strftime("%Y-%m-%d")}
    except:
        pass
    return None

def fetch_fund_live(fund_code: str):
    html = _fetch_html_tefas(fund_code)
    if html: return html
    api = _fetch_api_tefas(fund_code)
    if api: return api
    return None

# ============================================================
# ğŸ”¥ YENÄ°: KAP (Ä°Å YATIRIM) & TEFAS (PASTA) SCRAPER
# ============================================================

def _fetch_tefas_allocation(fund_code: str) -> Optional[List[Dict[str, Any]]]:
    """TEFAS'tan VarlÄ±k DaÄŸÄ±lÄ±mÄ±nÄ± (Pasta Grafik) Ã§eker"""
    print(f"ğŸ¥§ TEFAS Allocation deniyorum: {fund_code}")
    url = f"https://www.tefas.gov.tr/FonAnaliz.aspx?FonKod={fund_code.upper()}"
    headers = {"User-Agent": "Mozilla/5.0"}

    try:
        r = requests.get(url, headers=headers, timeout=10, verify=False)
        r.encoding = 'utf-8'
        if r.status_code == 200:
            match = re.search(r"data\s*:\s*(\[\[.*?\]\])", r.text, re.DOTALL)
            if match:
                raw = match.group(1).replace("'", '"')
                try:
                    data = json.loads(raw)
                    return [{"name": i[0], "value": float(i[1])} for i in data if len(i) == 2 and float(i[1]) > 0]
                except:
                    pass
    except Exception as e:
        print(f"âŒ TEFAS Allocation HatasÄ±: {e}")
    
    return None

def _fetch_kap_portfolio_from_isyatirim(fund_code: str) -> Optional[Dict[str, Any]]:
    """
    Ä°ÅŸ YatÄ±rÄ±m Fon Detay SayfasÄ±ndan KAP Verilerini Ã‡eker (Resmi Kaynak Scraper)
    CERRAH MODU: AFT gibi fon sepetleri veya karmaÅŸÄ±k tablolar iÃ§in iyileÅŸtirildi.
    """
    print(f"ğŸ›ï¸ Ä°ÅŸ YatÄ±rÄ±m (KAP) Verisi Ã‡ekiliyor: {fund_code}")
    
    url = f"https://www.isyatirim.com.tr/tr-tr/analiz/fonlar/Sayfalar/Fon-Detay.aspx?FonKodu={fund_code.upper()}"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36"
    }
    
    try:
        r = requests.get(url, headers=headers, timeout=12)
        r.encoding = 'utf-8' # Encoding fix
        if r.status_code != 200: return None
        
        soup = BeautifulSoup(r.text, "html.parser")
        details = {
            "positions": [],
            "increased": [], # Flutter null check hatasÄ± vermesin diye boÅŸ liste
            "decreased": [], # Flutter null check hatasÄ± vermesin diye boÅŸ liste
            "info": {"risk_value": 4, "founder": ""},
            "allocation": [] 
        }
        
        # 1. KURUCU BÄ°LGÄ°SÄ°
        h1 = soup.find("div", {"class": "page-title"})
        if h1:
            raw_title = h1.get_text(strip=True)
            if fund_code.upper() in raw_title:
                parts = raw_title.split(fund_code.upper())
                if len(parts) > 1:
                    details["info"]["founder"] = parts[1].strip(" -")
        
        # 2. RÄ°SK DEÄERÄ°
        risk_elem = soup.find(string=re.compile("Risk DeÄŸeri"))
        if risk_elem:
            try:
                parent = risk_elem.find_parent("tr") or risk_elem.find_parent("div")
                if parent:
                    txt = parent.get_text(strip=True)
                    match = re.search(r"Risk DeÄŸeri.*?(\d)", txt)
                    if match:
                        details["info"]["risk_value"] = int(match.group(1))
            except:
                pass

        # 3. EN BÃœYÃœK POZÄ°SYONLAR (GeliÅŸmiÅŸ Tablo Bulma - VAKUM MODU)
        tables = soup.find_all("table")
        candidates = [] # OlasÄ± tablolar

        for table in tables:
            rows = table.find_all("tr")
            if len(rows) < 2: continue # BaÅŸlÄ±k + en az 1 veri olmalÄ±
            
            temp_list = []
            
            for row in rows[1:]:
                cols = row.find_all("td")
                if len(cols) >= 2:
                    name_code = cols[0].get_text(strip=True)
                    ratio_str = cols[1].get_text(strip=True)
                    
                    if not ratio_str: continue

                    try:
                        ratio = _parse_turkish_float(ratio_str)
                        clean_code = name_code.strip().upper()
                        
                        if len(clean_code) > 2 and "TOPLAM" not in clean_code:
                            if "(" in clean_code:
                                clean_code = clean_code.split("(")[0].strip()
                            
                            if ratio > 0.01: # %0.01 Ã¼stÃ¼
                                temp_list.append({"code": clean_code, "ratio": ratio})
                    except:
                        continue
            
            if len(temp_list) > 0:
                candidates.append(temp_list)

        # En iyi adayÄ± seÃ§
        if candidates:
            candidates.sort(key=len, reverse=True)
            details["positions"] = candidates[0]
            details["positions"].sort(key=lambda x: x["ratio"], reverse=True)

        print(f"âœ… Ä°ÅŸ YatÄ±rÄ±m Data: {len(details['positions'])} pozisyon, Risk: {details['info']['risk_value']}")
        return details

    except Exception as e:
        print(f"âŒ Ä°ÅŸ YatÄ±rÄ±m Scraping Error: {e}")
        return None

# ============================================================
# ğŸ”¥ YENÄ°: HÄ°SSE BAZLI AI SKORLAMA (LIVE STOCK DATA ILE)
# ============================================================
def _load_live_stocks() -> Dict[str, float]:
    prices = {}
    if os.path.exists(STOCKS_LIVE_PRICES_PATH):
        try:
            with open(STOCKS_LIVE_PRICES_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
                if isinstance(data, list):
                    for item in data:
                        sym = item.get("symbol", "").replace(".IS", "")
                        chg = item.get("chgPct", 0.0)
                        prices[sym] = float(chg)
                elif isinstance(data, dict) and "data" in data:
                     for item in data["data"]:
                        sym = item.get("symbol", "").replace(".IS", "")
                        chg = item.get("chgPct", 0.0)
                        prices[sym] = float(chg)
        except:
            pass
    return prices

def calculate_ai_prediction(yearly: float, daily: float, holdings: List[Dict[str, Any]] = None):
    # 1. Klasik (Baz) Skor
    d_val = daily if daily is not None else 0.0
    
    direction = "NÃ–TR"
    confidence = 50
    
    if yearly > 40:
        confidence += 20
        direction = "POZÄ°TÄ°F"
    elif yearly < 0:
        confidence += 10
        direction = "NEGATÄ°F"

    # 2. HÄ°SSE BAZLI CANLI SKOR
    stock_impact = 0.0
    
    if holdings:
        live_stocks = _load_live_stocks()
        if live_stocks:
            total_w = 0.0
            weighted_change = 0.0
            
            for h in holdings:
                code = h.get("code", "")
                ratio = h.get("ratio", 0.0)
                
                clean_code = code.replace(".E", "").strip()
                
                live_chg = live_stocks.get(clean_code)
                if live_chg is None:
                     live_chg = live_stocks.get(clean_code + ".IS")

                if live_chg is not None:
                    weighted_change += (live_chg * ratio)
                    total_w += ratio
            
            stock_impact = weighted_change / 100.0
            
            if stock_impact > 0.15:
                direction = "POZÄ°TÄ°F"
                confidence = min(95, confidence + 25)
            elif stock_impact < -0.15:
                direction = "NEGATÄ°F"
                confidence = min(95, confidence + 25)

    estimated_return = stock_impact
    if not holdings or stock_impact == 0.0:
        estimated_return = d_val
        
    if estimated_return > 0.10:
        direction = "POZÄ°TÄ°F"
    elif estimated_return < -0.10:
        direction = "NEGATÄ°F"
    else:
        direction = "NÃ–TR"

    return direction, confidence, estimated_return

def get_fund_data_safe(fund_code: str):
    """
    GÃœNDE 1 KEZ TEFAS + KAP ENTEGRASYONLU VERÄ° Ã‡EKER
    """
    fund_code = fund_code.upper()
    effective_day = tefas_effective_date()

    try:
        now = datetime.now(ZoneInfo("Europe/Istanbul"))
    except:
        now = datetime.now()
    before_open = now.hour < 9 or (now.hour == 9 and now.minute < 30)
    is_weekend = now.weekday() >= 5

    cached = _PRICE_CACHE.get(fund_code)

    if not cached:
        if os.path.exists(LIVE_PRICES_PATH):
            try:
                with open(LIVE_PRICES_PATH, "r", encoding="utf-8") as f:
                    disk_raw = json.load(f)
                disk_data = disk_raw.get("data", {}) if isinstance(disk_raw, dict) else {}
                if disk_data.get(fund_code):
                    cached = disk_data[fund_code]
                    _PRICE_CACHE[fund_code] = cached
            except:
                pass

    cached_asof = (cached.get("asof_day") or "").strip() if cached else ""
    
    has_details = False
    if cached and "details" in cached:
        d = cached["details"]
        if d.get("positions") or d.get("info", {}).get("risk_value"):
            has_details = True

    is_new_fund = not cached
    force_fetch = False
    
    if is_new_fund:
        force_fetch = True
    elif not has_details: 
        force_fetch = True 
    elif cached_asof != effective_day:
        force_fetch = True

    if (not is_weekend) and before_open and not is_new_fund and has_details:
        force_fetch = False

    if not force_fetch and cached:
        return cached

    if not cached and not force_fetch:
        return {"nav": 0.0, "daily_return_pct": 0.0}

    with _TEFAS_LOCK:
        cached = _PRICE_CACHE.get(fund_code)
        
        has_details_inner = False
        if cached and "details" in cached:
             if cached["details"].get("positions") or cached["details"].get("info", {}).get("risk_value"):
                 has_details_inner = True

        if cached and cached.get("asof_day") == effective_day and has_details_inner:
            return cached

        print(f"ğŸš€ FORCE FETCH (X-RAY): {fund_code}")

        data = None
        if force_fetch:
            data = fetch_fund_live(fund_code)

        if data and data.get("price", 0) > 0:
            asof_day = (data.get("asof_day") or "").strip()
            if not asof_day:
                api_meta = _fetch_api_tefas(fund_code)
                asof_day = api_meta["asof_day"] if api_meta and "asof_day" in api_meta else effective_day

            safe_daily = data["daily_pct"] if data["daily_pct"] is not None else 0.0

            # ğŸ”¥ YENÄ°: DETAYLARI Ã‡EK (Ä°Å YATIRIM / KAP)
            details = _fetch_kap_portfolio_from_isyatirim(fund_code)
            
            # TEFAS'tan Allocation (Pasta Grafik) al
            allocation = _fetch_tefas_allocation(fund_code)
            
            if details:
                if allocation:
                     details["allocation"] = allocation 
            else:
                details = {
                    "positions": [],
                    "increased": [],
                    "decreased": [],
                    "info": {},
                    "allocation": allocation if allocation else []
                }

            # 4. TEFAS BACKUP (EÄŸer Ä°ÅŸ YatÄ±rÄ±m boÅŸ dÃ¶ndÃ¼yse ve TEFAS allocation varsa)
            # DFI gibi fonlarda KAP verisi olmayabilir, TEFAS'taki genel daÄŸÄ±lÄ±mÄ± kullan.
            if not details["positions"] and details.get("allocation"):
                for item in details["allocation"]:
                    details["positions"].append({
                        "code": item["name"],  # Ã–rn: "Hisse Senedi", "Mevduat"
                        "ratio": item["value"]
                    })
                details["positions"].sort(key=lambda x: x["ratio"], reverse=True)

            # ğŸ”¥ YENÄ°: AI Hesapla (Pozisyon verisiyle)
            holdings = details.get("positions", [])
            dir_str, conf, est_ret = calculate_ai_prediction(data["yearly_pct"], safe_daily, holdings)

            new_data = {
                "nav": data["price"],
                "daily_return_pct": safe_daily,
                "asof_day": asof_day,
                "last_update": asof_day + " 18:30:00",
                "source": data.get("source", "HTML"),
                "details": details, # âœ… ZENGÄ°N VERÄ° EKLENDÄ°
                "ai_prediction": {
                    "direction": dir_str,
                    "confidence": conf,
                    "score": round(data["yearly_pct"] / 12, 2),
                    "estimated_return": round(est_ret, 2) # âœ… YENÄ°
                },
            }

            _PRICE_CACHE[fund_code] = new_data
            save_memory_to_disk()
            return new_data
        
        elif force_fetch and cached:
             pass

    return cached if cached else {"nav": 0.0, "daily_return_pct": 0.0}

# ============================================================
# 4. MARKET DATA (BIST / USD) â€“ 15 DK
# ============================================================

def update_market_data():
    """BIST ve USD gÃ¼nceller"""
    items = []
    tickers = {"USDTRY": "USDTRY=X", "BIST100": "XU100.IS", "BIST30": "XU030.IS"}
    for c, s in tickers.items():
        try:
            t = yf.Ticker(s)
            info = t.fast_info
            p = info.last_price
            prev = info.previous_close
            pct = ((p - prev) / prev) * 100 if prev else 0.0
            items.append({"code": c, "value": round(p, 4), "change_pct": round(pct, 2)})
        except:
            items.append({"code": c, "value": 0.0, "change_pct": 0.0})

    try:
        _atomic_write_json(MARKET_CACHE_PATH, {"asof": now_str(), "items": items})
        print(f"ğŸ”„ Market Updated: {now_str()}")
    except Exception as e:
        print(f"âŒ Market write error: {e}")
    return items

def _get_market_change_pct(code: str) -> float:
    try:
        if os.path.exists(MARKET_CACHE_PATH):
            with open(MARKET_CACHE_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
            for it in data.get("items", []):
                if it.get("code") == code:
                    return float(it.get("change_pct", 0.0) or 0.0)
    except:
        pass
    return 0.0

# ============================================================
# 5. AI TAHMÄ°N (TEFAS YOK) â€“ 5 SN
# ============================================================

def get_ai_prediction_live(fund_code: str, daily_real: float) -> Dict[str, Any]:

    # ===============================
    # â° PÄ°YASA AÃ‡IK / KAPALI KONTROLÃœ
    # ===============================
    try:
        now_tr = datetime.now(ZoneInfo("Europe/Istanbul"))
    except:
        now_tr = datetime.now()

    # BIST: 09:30 â€“ 18:10 arasÄ± aÃ§Ä±k kabul edelim
    market_open = (
        (now_tr.hour > 9 or (now_tr.hour == 9 and now_tr.minute >= 30)) and
        (now_tr.hour < 18 or (now_tr.hour == 18 and now_tr.minute <= 10))
    )

    """
    ğŸ”’ Direction kilidi
    ğŸŒŠ YumuÅŸak jitter
    ğŸ§  Premium AI anchor
    TEFAS'a DOKUNMAZ
    """
    fund_code = fund_code.upper()
    now_ts = time.time()

    with _AI_LOCK:
        cached = _AI_CACHE.get(fund_code)
        
        # EÄŸer cached veri varsa ve "predicted_return_pct" yoksa (eski cache), yenile
        if cached and "predicted_return_pct" not in cached:
             cached = None

        # â›” PÄ°YASA KAPALIYSA â†’ CANLI AI KÄ°LÄ°TLENÄ°R
        if not market_open and cached:
            return cached

        # Market aÃ§Ä±ksa cache'i kÄ±salt
        try:
            now_tr = datetime.now(ZoneInfo("Europe/Istanbul"))
        except:
            now_tr = datetime.now()
        ttl = 1 if market_open else 3600  # KapalÄ±yken 1 saat kilit


        if cached and (now_ts - cached["_ts"]) < ttl:
            return cached

        # ===============================
        # MARKET VERÄ°LERÄ°
        # ===============================
        bist = _get_market_change_pct("BIST100")
        usd = _get_market_change_pct("USDTRY")

        # ===============================
        # ğŸ§  PREMIUM AI ANCHOR (TEK SATIR MANTIÄI)
        # ===============================
        master = _get_master_map_cached()
        rec = master.get(fund_code, {})
        fund_name = rec.get("name", "")
        fund_type = rec.get("type", "")

        premium = premium_build_prediction(
            fund_code=fund_code,
            fund_name=fund_name,
            fund_type_from_master=fund_type,
            daily_real_pct=daily_real,
            bist_change_pct=float(bist or 0.0),
            usd_change_pct=float(usd or 0.0),
            market_asof=now_str(),
        )
        premium_base = float(premium.get("predicted_return_pct", 0.0))

        # ===============================
        # ğŸŒŠ SOFT JITTER (Ã‡OK KÃœÃ‡ÃœK)
        # ===============================
        jitter = math.sin(now_ts / 60.0) * 0.03

        # ===============================
        # GÃœN Ä°Ã‡Ä° DRIFT (KAPANIÅA SIFIRLANIR)
        # ===============================
        try:
            dt = datetime.now(ZoneInfo("Europe/Istanbul"))
        except:
            dt = datetime.now()
        minutes = dt.hour * 60 + dt.minute
        session_pos = max(0.0, min(1.0, (minutes - 570) / (1090 - 570)))
        drift = 0.12 * (1.0 - session_pos)

        # ===============================
        # ğŸ¯ FÄ°NAL TAHMÄ°N (AÄIRLIKLI)
        # ===============================
        # EÄŸer cached veride hisse bazlÄ± tahmin varsa (estimated_return), onu da kat
        fund_data = _PRICE_CACHE.get(fund_code, {})
        holdings_impact = 0.0
        if "ai_prediction" in fund_data:
             holdings_impact = fund_data["ai_prediction"].get("estimated_return", 0.0)

        predicted = (
            premium_base * 0.50 +
            holdings_impact * 0.40 +
            daily_real * 0.10 +
            drift * 0.05 +
            jitter
        )
        predicted = round(predicted, 2)

        # ===============================
        # ğŸ”’ DIRECTION LOCK
        # ===============================
        prev = _AI_DIRECTION_LOCK.get(fund_code)

        raw_direction = (
            "POZÄ°TÄ°F" if predicted > 0
            else "NEGATÄ°F" if predicted < 0
            else "NÃ–TR"
        )

        direction = raw_direction

        if prev:
            # yÃ¶n deÄŸiÅŸimi iÃ§in eÅŸik
            if raw_direction != prev["direction"]:
                # kÃ¼Ã§Ã¼k deÄŸiÅŸimde yÃ¶nÃ¼ KORU
                if abs(predicted) < 0.25:
                    direction = prev["direction"]
                else:
                    # yÃ¶n deÄŸiÅŸti ama TS gÃ¼ncelle
                    _AI_DIRECTION_LOCK[fund_code] = {
                        "direction": raw_direction,
                        "ts": now_ts,
                    }
            else:
                direction = prev["direction"]
        else:
            _AI_DIRECTION_LOCK[fund_code] = {
                "direction": raw_direction,
                "ts": now_ts,
            }

        confidence = int(min(95, max(10, 55 + abs(predicted) * 10)))

        out = {
            "predicted_return_pct": predicted,
            "direction": direction,
            "confidence_score": confidence,
            "asof": now_str(),
            "_ts": now_ts,
        }

        _AI_CACHE[fund_code] = out
        return out

# ============================================================
# 6. OTOMATÄ°K ZAMANLAYICI (MARKET DATA Ä°Ã‡Ä°N)
# ============================================================

def auto_market_loop():
    """Server aÃ§Ä±k olduÄŸu sÃ¼rece her 15 dakikada bir Ã§alÄ±ÅŸÄ±r"""
    while True:
        update_market_data()
        time.sleep(900)  # 15 dakika bekle

# ============================================================
# 6.5 âœ… PREMIUM AI SUMMARY (TIP Ã–ZET + TOP FONLAR)
# ============================================================

def _safe_float(v: Any, default: float = 0.0) -> float:
    try:
        if v is None:
            return default
        if isinstance(v, (int, float)):
            return float(v)
        s = str(v).strip().replace(",", ".").replace("%", "")
        return float(s) if s else default
    except:
        return default

def _build_predictions_summary(scope: str = "portfolio") -> Dict[str, Any]:
    """
    scope:
      - "portfolio": sadece portfÃ¶ydeki fonlar
      - "all": funds_master iÃ§indeki tÃ¼m fonlar (1269 fon olabilir)
    """
    # market snapshot (premium_ai yardÄ±mcÄ±larÄ± ile)
    snap = read_market_snapshot(MARKET_CACHE_PATH)
    bist = market_change_pct(snap, "BIST100")
    usd = market_change_pct(snap, "USDTRY")
    market_asof = str(snap.get("asof") or "")

    master = _get_master_map_cached()

    # universe seÃ§imi
    codes: List[str] = []

    if scope == "all":
        codes = list(master.keys())
    else:
        # portfolio
        if os.path.exists(PORTFOLIO_PATH):
            try:
                with open(PORTFOLIO_PATH, "r", encoding="utf-8") as f:
                    raw = json.load(f)
                for pos in raw.get("positions", []):
                    c = str(pos.get("code") or "").upper().strip()
                    if c:
                        codes.append(c)
            except:
                codes = []

    # compute predictions
    items: List[Dict[str, Any]] = []
    by_type_acc: Dict[str, Dict[str, float]] = {}  # type -> {sum, cnt}

    for code in codes:
        rec = master.get(code, {}) if isinstance(master, dict) else {}
        fund_name = str(rec.get("name") or "")
        fund_type = str(rec.get("type") or "")

        # ğŸ“Œ RAM cache yoksa Disk cache'ten oku
        info = _PRICE_CACHE.get(code)
        
        if not info:
            if os.path.exists(LIVE_PRICES_PATH):
                try:
                    with open(LIVE_PRICES_PATH, "r", encoding="utf-8") as f:
                        disk_raw = json.load(f)
                    disk_data = disk_raw.get("data", {})
                    info = disk_data.get(code, {})
                except:
                    info = {}

        daily_real = _safe_float(info.get("daily_return_pct") if info else 0.0, 0.0)

        out = premium_build_prediction(
            fund_code=code,
            fund_name=fund_name,
            fund_type_from_master=fund_type,
            daily_real_pct=daily_real,
            bist_change_pct=float(bist or 0.0),
            usd_change_pct=float(usd or 0.0),
            market_asof=market_asof,
        )

        pred = _safe_float(out.get("predicted_return_pct"), 0.0)
        conf = int(_safe_float(out.get("confidence_score"), 50))
        direction = str(out.get("direction") or "NOTR")
        typ = str(out.get("meta", {}).get("fund_type") or fund_type or "DIGER")

        items.append({
            "code": code,
            "name": fund_name,
            "type": typ,
            "predicted_return_pct": round(pred, 2),
            "confidence_score": conf,
            "direction": direction,
        })

        acc = by_type_acc.get(typ)
        if not acc:
            by_type_acc[typ] = {"sum": pred, "cnt": 1.0}
        else:
            acc["sum"] += pred
            acc["cnt"] += 1.0

    # by_type averages
    by_type = []
    for t, acc in by_type_acc.items():
        cnt = int(acc["cnt"])
        avg = (acc["sum"] / acc["cnt"]) if acc["cnt"] else 0.0
        by_type.append({
            "type": t,
            "avg_pct": round(avg, 2),
            "count": cnt,
        })

    # sort by avg desc (kurumsal gÃ¶rÃ¼nÃ¼m)
    by_type.sort(key=lambda x: x.get("avg_pct", 0.0), reverse=True)

    # top funds: pred desc, conf >= 65
    top_funds = [x for x in items if int(x.get("confidence_score", 0)) >= 65]
    top_funds.sort(key=lambda x: (x.get("predicted_return_pct", 0.0), x.get("confidence_score", 0)), reverse=True)
    
    # âœ… FIX 3: Fallback mekanizmasÄ± (Liste asla boÅŸ dÃ¶nmesin)
    if not top_funds:
        items.sort(key=lambda x: (x.get("predicted_return_pct", 0.0), x.get("confidence_score", 0)), reverse=True)
        top_funds = items[:8]
    else:
        top_funds = top_funds[:8]

    return {
        "status": "success",
        "asof": now_str(),
        "scope": scope,
        "market": {
            "asof": market_asof,
            "bist_change_pct": round(float(bist or 0.0), 2),
            "usd_change_pct": round(float(usd or 0.0), 2),
        },
        "by_type": by_type,
        "top_funds": top_funds,
        "count": len(items),
    }

# ============================================================
# 7. YENÄ°: OTOMATÄ°K GÃœNCELLEME SÄ°STEMÄ°
# ============================================================

def update_newly_added_funds(fund_codes: List[str]):
    """
    Yeni eklenen fonlarÄ± hemen gÃ¼nceller
    """
    if not fund_codes:
        return
        
    print(f"ğŸš€ Yeni eklenen fonlar gÃ¼ncelleniyor: {', '.join(fund_codes)}")
    
    for i, code in enumerate(fund_codes, 1):
        print(f"ğŸ“ˆ [{i}/{len(fund_codes)}] GÃ¼ncelleniyor: {code}")
        try:
            result = get_fund_data_safe(code)
            if result and result.get("nav", 0) > 0:
                print(f"âœ… {code} baÅŸarÄ±yla gÃ¼ncellendi - Fiyat: {result['nav']:.4f}")
            else:
                print(f"âŒ {code} gÃ¼ncellenemedi - Veri alÄ±namadÄ±")
        except Exception as e:
            print(f"ğŸ’¥ {code} gÃ¼ncelleme hatasÄ±: {str(e)}")
        
        time.sleep(0.4)  # Ban korumasÄ±
    
    print(f"ğŸ¯ TÃ¼m yeni fonlar iÅŸlendi: {len(fund_codes)} adet")

# âœ… GÃœNCELLENDÄ°: "Any" yerine tÃ¼m portfÃ¶yÃ¼n gÃ¼ncel olup olmadÄ±ÄŸÄ±nÄ± kontrol eder ve timezone dÃ¼zeltmesi
def maybe_update_portfolio_funds():
    """
    09:30 sonrasÄ± portfÃ¶y fonlarÄ±nÄ± GÃœNDE 1 KEZ (effective_day bazlÄ±) tamamlar.
    """
    # EÄŸer server restart olmuÅŸsa (RAM cache boÅŸsa) gÃ¼nlÃ¼k kilidi resetle
    if not _PRICE_CACHE:
        _save_portfolio_update_day("")

    try:
        now = datetime.now(ZoneInfo("Europe/Istanbul"))
    except:
        now = datetime.now()
    if now.hour < 9 or (now.hour == 9 and now.minute < 30):
        return

    today = now.strftime("%Y-%m-%d")
    effective_day = tefas_effective_date()
    run_day = effective_day  # âœ… State anahtarÄ± bu olmalÄ±

    with _PORTFOLIO_UPDATE_LOCK:
        # PortfÃ¶y yoksa state yazÄ±p Ã§Ä±k
        if not os.path.exists(PORTFOLIO_PATH):
            _save_portfolio_update_day(run_day)
            return

        # PortfÃ¶y kodlarÄ±nÄ± oku
        try:
            with open(PORTFOLIO_PATH, "r", encoding="utf-8") as f:
                raw = json.load(f)
            codes = [
                (p.get("code") or "").upper().strip()
                for p in raw.get("positions", [])
                if p.get("code")
            ]
        except Exception as e:
            print(f"âŒ PortfÃ¶y okuma hata: {e}")
            return

        # Eksikleri bul (RAM + disk Ã¼zerinden)
        missing = _missing_codes_for_day(codes, effective_day)
        last_day = _load_portfolio_update_day()

        # âœ… SADECE: run_day state yazÄ±lmÄ±ÅŸ VE portfÃ¶yde eksik yoksa erken Ã§Ä±k
        if last_day == run_day and not missing:
            return

        # Eksik yoksa state'i dÃ¼zelt ve Ã§Ä±k
        if not missing:
            _save_portfolio_update_day(run_day)
            return

        print(f"ğŸ”„ PortfÃ¶y auto-update: {len(missing)}/{len(codes)} fon eksik, gÃ¼ncellenecek. effective_day={effective_day}")

        # Sadece eksikleri gÃ¼ncelle
        for code in missing:
            try:
                get_fund_data_safe(code)
            except Exception as e:
                print(f"âŒ PortfÃ¶y update hata ({code}): {e}")
            time.sleep(0.4)  # ğŸ”’ BAN KORUMASI

        # GÃ¼n bitti (portfÃ¶y tamamlandÄ± mÄ± kontrol et) â†’ state yaz
        missing2 = _missing_codes_for_day(codes, effective_day)
        if not missing2:
            _save_portfolio_update_day(run_day)
            print(f"âœ… PortfÃ¶y fonlarÄ± tamamlandÄ± ({run_day})")
        else:
            print(f"âš ï¸ PortfÃ¶y fonlarÄ± kÄ±smi kaldÄ±: {len(missing2)} fon hÃ¢lÃ¢ eksik; sonraki istekte tekrar denenecek.")

# âœ… GÃœNCELLENDÄ°: "Any" yerine tÃ¼m canlÄ± listenin gÃ¼ncel olup olmadÄ±ÄŸÄ±nÄ± kontrol eder ve timezone dÃ¼zeltmesi
def maybe_update_live_list_funds():
    """
    09:30 sonrasÄ± canlÄ± listedeki fonlarÄ± GÃœNDE 1 KEZ (effective_day bazlÄ±) tamamlar.
    """
    # EÄŸer server restart olmuÅŸsa (RAM cache boÅŸsa) gÃ¼nlÃ¼k kilidi resetle
    if not _PRICE_CACHE:
        _save_live_list_update_day("")

    try:
        now = datetime.now(ZoneInfo("Europe/Istanbul"))
    except:
        now = datetime.now()
    if now.hour < 9 or (now.hour == 9 and now.minute < 30):
        return

    today = now.strftime("%Y-%m-%d")
    effective_day = tefas_effective_date()
    run_day = effective_day  # âœ… State anahtarÄ± bu olmalÄ±

    with _LIVE_LIST_UPDATE_LOCK:
        # Liste yoksa state yazÄ±p Ã§Ä±k
        if not os.path.exists(LIVE_LIST_PATH):
            _save_live_list_update_day(run_day)
            return

        # Liste kodlarÄ±nÄ± oku
        try:
            with open(LIVE_LIST_PATH, "r", encoding="utf-8") as f:
                raw = json.load(f)
            codes = [
                (item.get("code") or "").upper().strip()
                for item in raw.get("items", [])
                if item.get("code")
            ]
        except Exception as e:
            print(f"âŒ CanlÄ± liste okuma hata: {e}")
            return

        # Eksikleri bul
        missing = _missing_codes_for_day(codes, effective_day)
        last_day = _load_live_list_update_day()

        # âœ… SADECE: run_day state yazÄ±lmÄ±ÅŸ VE listede eksik yoksa erken Ã§Ä±k
        if last_day == run_day and not missing:
            return

        # Eksik yoksa state'i dÃ¼zelt ve Ã§Ä±k
        if not missing:
            _save_live_list_update_day(run_day)
            return

        print(f"ğŸ”„ CanlÄ± liste auto-update: {len(missing)}/{len(codes)} fon eksik, gÃ¼ncellenecek. effective_day={effective_day}")

        # Sadece eksikleri gÃ¼ncelle
        for code in missing:
            try:
                get_fund_data_safe(code)
            except Exception as e:
                print(f"âŒ CanlÄ± liste update hata ({code}): {e}")
            time.sleep(0.4)  # Ban korumasÄ±

        # GÃ¼n bitti mi kontrol et â†’ state yaz
        missing2 = _missing_codes_for_day(codes, effective_day)
        if not missing2:
            _save_live_list_update_day(run_day)
            print(f"âœ… CanlÄ± liste fonlarÄ± tamamlandÄ± ({run_day})")
        else:
            print(f"âš ï¸ CanlÄ± liste fonlarÄ± kÄ±smi kaldÄ±: {len(missing2)} fon hÃ¢lÃ¢ eksik; sonraki istekte tekrar denenecek.")

# ============================================================
# 8. API ENDPOINTS
# ============================================================

@router.get("/admin/refresh")
def api_refresh():
    m = update_market_data()
    return {"status": "success", "message": "Piyasa GÃ¼ncellendi.", "market": m}

@router.get("/market")
def api_market():
    data = {"items": []}
    if os.path.exists(MARKET_CACHE_PATH):
        try:
            with open(MARKET_CACHE_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
        except:
            pass
    return {"status": "success", "data": {"market": data}}

@router.get("/predictions/summary")
def api_predictions_summary(scope: str = "portfolio"):
    """
    âœ… Yeni endpoint:
      GET /funds/predictions/summary?scope=portfolio
      GET /funds/predictions/summary?scope=all

    DÃ¶ner:
      by_type: tip bazlÄ± ortalamalar
      top_funds: gÃ¼Ã§lÃ¼ fonlar listesi
    """
    global _PRED_SUMMARY_CACHE, _PRED_SUMMARY_TS
    scope = (scope or "portfolio").strip().lower()
    if scope not in ("portfolio", "all"):
        scope = "portfolio"

    # âœ… PATCH 3.4: 15 sn cache (scope bazlÄ±)
    with _PRED_SUMMARY_LOCK:
        ts = time.time()
        cached = _PRED_SUMMARY_CACHE.get(scope)
        last_ts = _PRED_SUMMARY_TS.get(scope, 0.0)
        if cached and (ts - last_ts) < _PRED_SUMMARY_TTL_SEC:
            return cached

    data = _build_predictions_summary(scope=scope)

    # âœ… PATCH 3.6: TS scope bazlÄ± update
    with _PRED_SUMMARY_LOCK:
        _PRED_SUMMARY_CACHE[scope] = data
        _PRED_SUMMARY_TS[scope] = time.time()

    return data

@router.get("/portfolio")
def api_portfolio():
    # ğŸ”¥ 09:30 sonrasÄ± otomatik portfÃ¶y gÃ¼ncelleme
    maybe_update_portfolio_funds()

    if os.path.exists(PORTFOLIO_PATH):
        try:
            with open(PORTFOLIO_PATH, "r", encoding="utf-8") as f:
                raw_portfolio = json.load(f)
        except:
            raw_portfolio = {"positions": []}
    else:
        raw_portfolio = {"positions": []}

    result_list = []
    for pos in raw_portfolio.get("positions", []):
        code = (pos.get("code") or "").upper().strip()
        if not code:
            continue
        qty = float(pos.get("quantity", 0) or 0)

        # TEFAÅ cacheli gerÃ§ek veri (gÃ¼nde 1 kere)
        info = get_fund_data_safe(code)
        daily_real = float(info.get("daily_return_pct", 0.0) or 0.0)

        # AI tahmin (sadece yÃ¶n iÃ§in)
        ai = get_ai_prediction_live(code, daily_real)

        # ğŸ¯ Ã‡Ã–ZÃœM: Mobil app'in beklediÄŸi alanlarÄ± gerÃ§ek TEFAÅ verilerine baÄŸla
        result_list.append({
            "code": code,
            "quantity": qty,
            "nav": info.get("nav", 0.0),
            "daily_return_pct": daily_real,                    # âœ… TEFAÅ gerÃ§ek %
            
            # ğŸ¯ Ã‡Ã–ZÃœM: Mobil'in predicted_return_pct alanÄ±na AI TAHMÄ°NÄ° koy (Fix 2)
            "predicted_return_pct": ai.get("predicted_return_pct", daily_real), 
            "confidence_score": ai.get("confidence_score", 50),
            "direction": ai.get("direction", "NÃ–TR"),
            
            "value": qty * float(info.get("nav", 0.0) or 0.0),

            # ESKÄ° alanÄ± koru (mevcut sistemle uyumlu)
            "prediction": info.get("ai_prediction", {}),
        })

    return {"status": "success", "data": result_list}

@router.post("/portfolio/set")
def api_pset(payload: Dict[str, Any]):
    """
    payload: {"positions":[{"code":"AFT","quantity":10}, ...]}
    
    YENÄ°: Fon eklendiÄŸinde otomatik gÃ¼ncelleme
    """
    try:
        positions = payload.get("positions", [])
        
        # âœ… YENÄ°: Ã–nceki fon kodlarÄ±nÄ± oku
        previous_codes = _get_portfolio_codes()
        
        # PortfÃ¶yÃ¼ kaydet
        with open(PORTFOLIO_PATH, "w", encoding="utf-8") as f:
            json.dump({"asof": now_str(), "positions": positions}, f, ensure_ascii=False, indent=2)
        
        # âœ… YENÄ°: Yeni eklenen fonlarÄ± tespit et ve gÃ¼ncelle
        current_codes = [str(pos.get("code") or "").upper().strip() for pos in positions if pos.get("code")]
        new_funds = _get_newly_added_funds(previous_codes, current_codes)
        
        if new_funds:
            print(f"ğŸ†• Yeni fonlar tespit edildi: {', '.join(new_funds)}")
            update_newly_added_funds(new_funds)
        
    except:
        pass
    return {"status": "success"}

@router.get("/list")
def api_list():
    if os.path.exists(FUNDS_MASTER_PATH):
        try:
            with open(FUNDS_MASTER_PATH, "r", encoding="utf-8") as f:
                master = json.load(f)
        except:
            master = []
    else:
        master = []
    return {"status": "success", "data": {"items": master}}

@router.get("/live-list")
def api_live_list():
    """
    âœ… YENÄ°: CanlÄ± liste endpoint'i
    09:30 sonrasÄ± otomatik gÃ¼ncelleme yapar
    """
    # 09:30 sonrasÄ± otomatik canlÄ± liste gÃ¼ncelleme
    maybe_update_live_list_funds()
    
    if os.path.exists(LIVE_LIST_PATH):
        try:
            with open(LIVE_LIST_PATH, "r", encoding="utf-8") as f:
                raw_list = json.load(f)
        except:
            raw_list = {"items": []}
    else:
        raw_list = {"items": []}

    result_list = []
    for item in raw_list.get("items", []):
        code = (item.get("code") or "").upper().strip()
        if not code:
            continue

        # TEFAÅ cacheli gerÃ§ek veri (gÃ¼nde 1 kere)
        info = get_fund_data_safe(code)
        daily_real = float(info.get("daily_return_pct", 0.0) or 0.0)

        # AI tahmin
        ai = get_ai_prediction_live(code, daily_real)

        result_list.append({
            "code": code,
            "name": item.get("name", ""),
            "nav": info.get("nav", 0.0),
            "daily_return_pct": daily_real,
            "predicted_return_pct": ai.get("predicted_return_pct", daily_real),
            "confidence_score": ai.get("confidence_score", 50),
            "direction": ai.get("direction", "NÃ–TR"),
            "type": item.get("type", ""),
        })

    return {"status": "success", "data": result_list}

@router.post("/live-list/set")
def api_live_list_set(payload: Dict[str, Any]):
    """
    payload: {"items":[{"code":"AFT","name":"..."}, ...]}
    
    YENÄ°: CanlÄ± listeye fon eklendiÄŸinde otomatik gÃ¼ncelleme
    """
    try:
        items = payload.get("items", [])
        
        # âœ… YENÄ°: Ã–nceki fon kodlarÄ±nÄ± oku
        previous_codes = _get_live_list_codes()
        
        # CanlÄ± listeyi kaydet
        with open(LIVE_LIST_PATH, "w", encoding="utf-8") as f:
            json.dump({"asof": now_str(), "items": items}, f, ensure_ascii=False, indent=2)
        
        # âœ… YENÄ°: Yeni eklenen fonlarÄ± tespit et ve gÃ¼ncelle
        current_codes = [str(item.get("code") or "").upper().strip() for item in items if item.get("code")]
        new_funds = _get_newly_added_funds(previous_codes, current_codes)
        
        if new_funds:
            print(f"ğŸ†• CanlÄ± listeye yeni fonlar eklendi: {', '.join(new_funds)}")
            update_newly_added_funds(new_funds)
        
    except:
        pass
    return {"status": "success"}

@router.get("/detail/{code}")
def api_detail(code: str):
    # Detayda cacheli hÄ±zlÄ± dÃ¶n (gÃ¼nde 1 TEFAS)
    info = get_fund_data_safe(code)
    if info.get("nav", 0) > 0:
        daily_real = float(info.get("daily_return_pct", 0.0) or 0.0)
        ai = get_ai_prediction_live(code.upper(), daily_real)
        
        # EÄŸer Fintables'tan gelen detaylÄ± AI skoru varsa (hisse bazlÄ±), onu da ekle
        predicted_return = ai.get("predicted_return_pct", daily_real)
        if "ai_prediction" in info and "estimated_return" in info["ai_prediction"]:
             # Cache'teki hisse bazlÄ± skoru kullanabiliriz, ama live market data daha taze
             # O yÃ¼zden get_ai_prediction_live fonksiyonu zaten bunu birleÅŸtiriyor.
             pass

        return {
            "status": "success",
            "data": {
                **info,
                # ğŸ¯ Ã‡Ã–ZÃœM: Mobil kolay kullansÄ±n diye dÃ¼z alanlar (Fix 2)
                "predicted_return_pct": predicted_return,
                "confidence_score": ai.get("confidence_score", 50),
                "direction": ai.get("direction", "NÃ–TR"),
            }
        }
    return {"status": "error", "message": "Veri yok"}

# @router.get("/admin/refresh-tefas")
# def admin_refresh_tefas():
#     """
#     TEFAS toplu batch scrape.
#     Runtime API'yi etkilemez.
#     """
#     result = run_batch_scrape()
#     return {
#         "status": "success",
#         "message": "TEFAS batch scrape tamamlandÄ±",
#         "result": result
#     }

# âœ… EKLENDÄ°: Server aÃ§Ä±lÄ±ÅŸÄ±nda bootstrap gÃ¼ncellemesi
def _startup_bootstrap_updates():
    # Uvicorn import sÄ±rasÄ±nda hemen saldÄ±rmasÄ±n, biraz bekle
    time.sleep(2)

    # Server 09:30 sonrasÄ± aÃ§Ä±ldÄ±ysa anÄ±nda dene; deÄŸilse endpoint zaten tetikler.
    try:
        maybe_update_portfolio_funds()
    except Exception as e:
        print(f"âŒ Startup portfolio bootstrap hata: {e}")

    try:
        maybe_update_live_list_funds()
    except Exception as e:
        print(f"âŒ Startup live-list bootstrap hata: {e}")

# âœ… PATCH 4.2: Threadleri tek sefer baÅŸlat (reload-safe)
def _start_background_jobs_once():
    """Uvicorn reload / Ã§oklu import durumunda thread'leri tek sefer baÅŸlat."""
    global _BG_STARTED
    with _BG_LOCK:
        if _BG_STARTED:
            return
        _BG_STARTED = True

        # 1) Cache'i RAM'e yÃ¼kle
        load_cache_to_memory()

        # 2) Market loop thread
        t_market = threading.Thread(target=auto_market_loop, daemon=True)
        t_market.start()

        # 3) Startup bootstrap thread
        t_boot = threading.Thread(target=_startup_bootstrap_updates, daemon=True)
        t_boot.start()

# âœ… Import olur olmaz Ã§alÄ±ÅŸtÄ±r (ama tek sefer)
_start_background_jobs_once()
