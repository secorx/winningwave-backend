# Fon Otomatik GÃ¼ncelleme Sistemi
# Bu kodu mevcut funds.py dosyanÄ±zÄ±n yerine koyun - TAM VE EKSÄ°KSÄ°Z VERSÄ°RON

from __future__ import annotations

import os
import json
import time
import threading
import math
import re
import requests
import urllib3
import yfinance as yf
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional
from bs4 import BeautifulSoup  # âœ… EKLENDÄ°: HTML Parsing iÃ§in

try:
    from zoneinfo import ZoneInfo
except Exception:
    ZoneInfo = None
  # âœ… EKLENDÄ°: Haftasonu ve saat dÃ¼zeltmesi iÃ§in

from fastapi import APIRouter

# âœ… EKLENDÄ°: Premium AI araÃ§larÄ± (summary iÃ§in)
from api.premium_ai import (
    build_premium_prediction as premium_build_prediction,
    load_funds_master_map,
    read_market_snapshot,
    market_change_pct,
)


# ============================================================
# CACHE BASE DIR (LOCAL vs RENDER SAFE)
# ============================================================

BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))

CACHE_ROOT = os.getenv(
    "CACHE_ROOT",
    BASE_DIR  # local default
)

CACHE_DIR = os.path.join(CACHE_ROOT, "funds_cache")
os.makedirs(CACHE_DIR, exist_ok=True)

# âœ… DATA DIR (HER ZAMAN PROJE Ä°Ã‡Ä°NDE)
DATA_DIR = os.path.join(BASE_DIR, "data")
os.makedirs(DATA_DIR, exist_ok=True)



# SSL UyarÄ±larÄ±nÄ± Kapat
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

router = APIRouter(tags=["funds"])

# ============================================================
# 1. AYARLAR & GLOBAL HAFIZA (OTOMATÄ°K ROOT TESPÄ°TÄ°)
# ============================================================

def _detect_project_root() -> str:
    """
    funds.py hangi klasÃ¶rde olursa olsun proje root'unu bulmaya Ã§alÄ±ÅŸÄ±r.
    Ã–ncelik: iÃ§inde funds_cache veya data klasÃ¶rÃ¼ olan Ã¼st dizin.
    """
    here = os.path.abspath(os.path.dirname(__file__))
    candidates = [
        os.path.abspath(os.path.join(here, "..")),        # 1 Ã¼st
        os.path.abspath(os.path.join(here, "..", "..")),  # 2 Ã¼st
        os.path.abspath(os.path.join(here, "..", "..", "..")),  # 3 Ã¼st
    ]
    for c in candidates:
        if os.path.isdir(os.path.join(c, "funds_cache")) or os.path.isdir(os.path.join(c, "data")):
            return c
    # fallback
    return candidates[0]

FUNDS_MASTER_PATH = os.path.join(DATA_DIR, "funds_master.json")
LIVE_PRICES_PATH = os.path.join(CACHE_DIR, "live_prices.json")
# âœ… HÄ°SSE FÄ°YATLARI Ä°Ã‡Ä°N (AI HESAPLAMASINDA KULLANILACAK)
STOCKS_LIVE_PRICES_PATH = os.path.join(DATA_DIR, "live_prices.json") 

PORTFOLIO_PATH = os.path.join(CACHE_DIR, "portfolio.json")
MARKET_CACHE_PATH = os.path.join(CACHE_DIR, "market_cache.json")
PREDICTION_CACHE_PATH = os.path.join(CACHE_DIR, "prediction_cache.json")

# âœ… YENÄ°: CanlÄ± liste dosyasÄ±
LIVE_LIST_PATH = os.path.join(CACHE_DIR, "live_list.json")

# âœ… YENÄ°: PortfÃ¶y gÃ¼ncelleme durumu iÃ§in dosya yolu
PORTFOLIO_UPDATE_STATE_PATH = os.path.join(CACHE_DIR, "portfolio_update_state.json")
# âœ… YENÄ°: CanlÄ± liste gÃ¼ncelleme durumu iÃ§in dosya yolu
LIVE_LIST_UPDATE_STATE_PATH = os.path.join(CACHE_DIR, "live_list_update_state.json")

# âœ… YENÄ°: Fetch Tracking Path (Tekrar Ã§ekimi Ã¶nlemek iÃ§in - ArtÄ±k logic iÃ§inde kullanÄ±lmÄ±yor ama dosya tanÄ±mÄ± kalsÄ±n)
FETCH_TRACKING_PATH = os.path.join(CACHE_DIR, "fetch_tracking.json")

os.makedirs(CACHE_DIR, exist_ok=True)
os.makedirs(DATA_DIR, exist_ok=True)

# RAM CACHE (TEFAS iÃ§in)
_PRICE_CACHE: Dict[str, Dict] = {}
_TEFAS_LOCK = threading.Lock()

# AI TAHMÄ°N CACHE (TEFAS'SIZ, 5 sn)
_AI_CACHE: Dict[str, Dict[str, Any]] = {}
_AI_LOCK = threading.Lock()

# ğŸ”’ Direction Lock Cache
_AI_DIRECTION_LOCK: Dict[str, Dict[str, Any]] = {}

# âœ… EKLENDÄ°: funds_master map cache (type/name iÃ§in)
_MASTER_MAP: Dict[str, Dict[str, Any]] = {}
_MASTER_MAP_TS: float = 0.0
_MASTER_LOCK = threading.Lock()
_MASTER_TTL_SEC = 3600  # 1 saat

# âœ… EKLENDÄ°: Predictions Summary cache (Ã§ok hÄ±zlÄ± UI iÃ§in)
_PRED_SUMMARY_CACHE: Dict[str, Any] = {}
# âœ… PATCH 3.1 & 3.2: Timestamp artÄ±k dict (scope bazlÄ±)
_PRED_SUMMARY_TS: Dict[str, float] = {}
_PRED_SUMMARY_LOCK = threading.Lock()
_PRED_SUMMARY_TTL_SEC = 15  # 15 sn cache (UI refresh iÃ§in yeterli)

# ================================
# ğŸ”’ Background jobs start guard (uvicorn --reload safe)
# ================================
# âœ… PATCH 0.1: Tek seferlik baÅŸlatma kilidi
_BG_STARTED = False
_BG_LOCK = threading.Lock()

# ================================
# GÃœNLÄ°K PORTFÃ–Y & CANLI LÄ°STE UPDATE KÄ°LÄ°DÄ°
# ================================
# Not: ArtÄ±k global deÄŸiÅŸken yerine diskten okuyoruz, sadece Lock kaldÄ±.
_PORTFOLIO_UPDATE_LOCK = threading.Lock()
_LIVE_LIST_UPDATE_LOCK = threading.Lock()

# ============================================================
# 2. YARDIMCI FONKSÄ°YONLAR
# ============================================================

# âœ… GÃœNCELLENDÄ°: now_str() Istanbul saatine gÃ¶re
def now_str() -> str:
    try:
        if ZoneInfo:
            return datetime.now(ZoneInfo("Europe/Istanbul")).strftime("%Y-%m-%d %H:%M:%S")
    except:
        pass
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


# âœ… GÃœNCELLENDÄ°: today_str() Istanbul saatine gÃ¶re
def today_str() -> str:
    try:
        if ZoneInfo:
            return datetime.now(ZoneInfo("Europe/Istanbul")).strftime("%Y-%m-%d")
    except:
        pass
    return datetime.now().strftime("%Y-%m-%d")

# âœ… YARDIMCI: Ã–nceki iÅŸ gÃ¼nÃ¼nÃ¼ bul
def _prev_business_day(d):
    d = d - timedelta(days=1)
    while d.weekday() >= 5:  # 5=Sat, 6=Sun
        d = d - timedelta(days=1)
    return d

# âœ… DÃœZELTÄ°LDÄ°: TEFAS Effective Date (Haftasonu + 09:30 KuralÄ±)
def tefas_effective_date() -> str:
    try:
        now = datetime.now(ZoneInfo("Europe/Istanbul"))
    except:
        now = datetime.now()

    today = now.date()
    after_0930 = (now.hour > 9) or (now.hour == 9 and now.minute >= 30)

    if today.weekday() >= 5:
        # Hafta sonu: TEFAS hÃ¢lÃ¢ PerÅŸembe'yi verir (Cuma verisi â€œyayÄ±nlanmÄ±ÅŸâ€ sayÄ±lmaz)
        d = _prev_business_day(_prev_business_day(today))
    else:
        if after_0930:
            # 09:30 sonrasÄ±: dÃ¼nÃ¼n iÅŸ gÃ¼nÃ¼
            d = _prev_business_day(today)
        else:
            # 09:30 Ã¶ncesi: iki Ã¶nceki iÅŸ gÃ¼nÃ¼
            d = _prev_business_day(_prev_business_day(today))

    return d.strftime("%Y-%m-%d")

# âœ… YENÄ°: PortfÃ¶y gÃ¼ncelleme durumunu diskten oku (Optional ile uyumlu)
def _load_portfolio_update_day() -> Optional[str]:
    if os.path.exists(PORTFOLIO_UPDATE_STATE_PATH):
        try:
            with open(PORTFOLIO_UPDATE_STATE_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
                return data.get("last_day")
        except:
            pass
    return None

# âœ… YENÄ°: PortfÃ¶y gÃ¼ncelleme durumunu diske yaz
def _save_portfolio_update_day(day: str):
    try:
        with open(PORTFOLIO_UPDATE_STATE_PATH, "w", encoding="utf-8") as f:
            json.dump({"last_day": day}, f, ensure_ascii=False)
    except:
        pass

# âœ… YENÄ°: CanlÄ± liste gÃ¼ncelleme durumunu diskten oku (Optional ile uyumlu)
def _load_live_list_update_day() -> Optional[str]:
    if os.path.exists(LIVE_LIST_UPDATE_STATE_PATH):
        try:
            with open(LIVE_LIST_UPDATE_STATE_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
                return data.get("last_day")
        except:
            pass
    return None

# âœ… YENÄ°: CanlÄ± liste gÃ¼ncelleme durumunu diske yaz
def _save_live_list_update_day(day: str):
    try:
        with open(LIVE_LIST_UPDATE_STATE_PATH, "w", encoding="utf-8") as f:
            json.dump({"last_day": day}, f, ensure_ascii=False)
    except:
        pass

# âœ… YENÄ°: FETCH TRACKING HELPER'LARI (ArtÄ±k aktif kullanÄ±lmÄ±yor ama dosya tanÄ±mÄ± kalsÄ±n)
def _load_fetch_tracking() -> Dict[str, str]:
    if os.path.exists(FETCH_TRACKING_PATH):
        try:
            with open(FETCH_TRACKING_PATH, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            pass
    return {}

def _save_fetch_tracking(data: Dict[str, str]):
    try:
        with open(FETCH_TRACKING_PATH, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except:
        pass

# âœ… GÃœNCELLENDÄ°: RAM CACHE Ä°Ã‡Ä°NDE GÃœNCEL VERÄ° KONTROLÃœ (asof_day bazlÄ±)
def _is_code_fresh(code: str, effective_day: str) -> bool:
    """
    Bir fon kodu effective_day iÃ§in gÃ¼ncel mi?
    - asof_day kontrol edilir.
    - RAM cache'e bakar, yoksa disk cache'ten bakar.
    """
    code = code.upper().strip()

    def check_rec(r: Dict) -> bool:
        if not r or r.get("nav", 0) <= 0:
            return False
        # âœ… Ã–ncelik asof_day
        rec_asof = str(r.get("asof_day") or "").strip()
        if rec_asof == effective_day:
            return True
        # asof_day yoksa (eski veri) ama last_update tutuyorsa (legacy)
        if not rec_asof and str(r.get("last_update", "")).startswith(effective_day):
            return True
        return False

    # 1) RAM check
    if check_rec(_PRICE_CACHE.get(code)):
        return True

    # 2) Disk check
    if os.path.exists(LIVE_PRICES_PATH):
        try:
            with open(LIVE_PRICES_PATH, "r", encoding="utf-8") as f:
                disk_raw = json.load(f)
            disk_data = disk_raw.get("data", {}) if isinstance(disk_raw, dict) else {}
            if check_rec(disk_data.get(code)):
                return True
        except:
            pass

    return False

def _missing_codes_for_day(codes: List[str], effective_day: str) -> List[str]:
    """codes iÃ§inden effective_day iÃ§in gÃ¼ncel olmayanlarÄ± dÃ¶ndÃ¼rÃ¼r."""
    out = []
    for c in codes:
        c2 = (c or "").upper().strip()
        if c2 and not _is_code_fresh(c2, effective_day):
            out.append(c2)
    return out

# âœ… YENÄ°: CanlÄ± listeden fon kodlarÄ±nÄ± oku
def _get_live_list_codes() -> List[str]:
    """CanlÄ± listedeki fon kodlarÄ±nÄ± dÃ¶ndÃ¼r"""
    codes = []
    if os.path.exists(LIVE_LIST_PATH):
        try:
            with open(LIVE_LIST_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
            for item in data.get("items", []):
                code = str(item.get("code") or "").upper().strip()
                if code:
                    codes.append(code)
        except:
            pass
    return codes

# âœ… YENÄ°: PortfÃ¶yden fon kodlarÄ±nÄ± oku
def _get_portfolio_codes() -> List[str]:
    """PortfÃ¶ydeki fon kodlarÄ±nÄ± dÃ¶ndÃ¼r"""
    codes = []
    if os.path.exists(PORTFOLIO_PATH):
        try:
            with open(PORTFOLIO_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
            for pos in data.get("positions", []):
                code = str(pos.get("code") or "").upper().strip()
                if code:
                    codes.append(code)
        except:
            pass
    return codes

# âœ… YENÄ°: Ä°lk defa eklenen fonlarÄ± tespit et
def _get_newly_added_funds(previous_codes: List[str], current_codes: List[str]) -> List[str]:
    """Yeni eklenen fon kodlarÄ±nÄ± dÃ¶ndÃ¼r"""
    prev_set = set(previous_codes)
    new_codes = [code for code in current_codes if code not in prev_set]
    return new_codes

# ğŸ“Œ DÃœZELTME 1: Unicode eksi iÅŸareti ve temizleme mantÄ±ÄŸÄ± gÃ¼ncellendi
def _parse_turkish_float(text: str) -> float:
    try:
        s = str(text)
        s = s.replace("âˆ’", "-")  # ğŸ”´ KRÄ°TÄ°K: unicode minus normalize
        s = re.sub(r"[^0-9,.-]", "", s)
        return float(s.replace(",", "."))
    except:
        return 0.0

# âœ… DÃœZELTÄ°LDÄ°: 1ï¸âƒ£ load_cache_to_memory()
def load_cache_to_memory():
    """Server aÃ§Ä±lÄ±nca diskteki veriyi RAM'e yÃ¼kler"""
    global _PRICE_CACHE
    
    if not os.path.exists(LIVE_PRICES_PATH):
        _PRICE_CACHE = {}
    else:
        try:
            with open(LIVE_PRICES_PATH, "r", encoding="utf-8") as f:
                raw = json.load(f)

            # âœ… KRÄ°TÄ°K: batch output iÃ§inden SADECE data'yÄ± al
            if isinstance(raw, dict) and "data" in raw:
                _PRICE_CACHE = raw["data"]
            else:
                _PRICE_CACHE = raw

            print(f"âœ… RAM cache yÃ¼klendi: {len(_PRICE_CACHE)} fon")

        except Exception as e:
            print(f"âŒ Cache yÃ¼klenedi: {e}")
            _PRICE_CACHE = {}

    # âœ… DEBUG PRINTS (Ä°STENÄ°LEN)
    print(f"ğŸ§­ BASE_DIR={BASE_DIR}")
    print(f"ğŸ§­ PORTFOLIO_PATH={PORTFOLIO_PATH} exists={os.path.exists(PORTFOLIO_PATH)}")
    print(f"ğŸ§­ LIVE_LIST_PATH={LIVE_LIST_PATH} exists={os.path.exists(LIVE_LIST_PATH)}")
    print(f"ğŸ§­ LIVE_PRICES_PATH={LIVE_PRICES_PATH} exists={os.path.exists(LIVE_PRICES_PATH)}")

# âœ… ADIM 3: KAYIT FORMATI DÃœZELTÄ°LDÄ° (Batch scraper uyumlu)
def save_memory_to_disk():
    """RAM cache'i diske atomik yaz"""
    try:
        tmp = LIVE_PRICES_PATH + ".tmp"
        with open(tmp, "w", encoding="utf-8") as f:
            json.dump(
                {"data": _PRICE_CACHE, "asof": now_str()},
                f,
                ensure_ascii=False,
                indent=2
            )
        os.replace(tmp, LIVE_PRICES_PATH)
    except Exception as e:
        print(f"âŒ save_memory_to_disk: {e}")

# âœ… PATCH 1.1: Atomik JSON yazma helper'Ä±
def _atomic_write_json(path: str, obj: Any):
    """JSON'u atomik yaz (yarÄ±m dosya / bozuk JSON riskini azaltÄ±r)."""
    try:
        tmp = path + ".tmp"
        with open(tmp, "w", encoding="utf-8") as f:
            json.dump(obj, f, ensure_ascii=False, indent=2)
        os.replace(tmp, path)
    except Exception as e:
        print(f"âŒ _atomic_write_json({path}): {e}")

# âœ… EKLENDÄ°: master map'i cacheli oku (type/name iÃ§in)
def _get_master_map_cached() -> Dict[str, Dict[str, Any]]:
    global _MASTER_MAP, _MASTER_MAP_TS
    ts = time.time()
    if _MASTER_MAP and (ts - _MASTER_MAP_TS) < _MASTER_TTL_SEC:
        return _MASTER_MAP

    with _MASTER_LOCK:
        ts = time.time()
        if _MASTER_MAP and (ts - _MASTER_MAP_TS) < _MASTER_TTL_SEC:
            return _MASTER_MAP
        _MASTER_MAP = load_funds_master_map(FUNDS_MASTER_PATH)
        _MASTER_MAP_TS = ts
        return _MASTER_MAP

# ============================================================
# 3. VERÄ° Ã‡EKME MOTORU (TEFAS)
# ============================================================

def _fetch_html(fund_code: str):
    print(f"ğŸŒ TEFAS HTML deniyorum: {fund_code}")
    url = f"https://www.tefas.gov.tr/FonAnaliz.aspx?FonKod={fund_code.upper()}"
    
    # ğŸ”§ ACÄ°L Ã‡Ã–ZÃœM: Daha gÃ¼Ã§lÃ¼ headers ve timeout
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        "Accept-Language": "tr-TR,tr;q=0.9,en-US;q=0.8,en;q=0.7",
        "Accept-Encoding": "gzip, deflate",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
        "Sec-Fetch-Dest": "document",
        "Sec-Fetch-Mode": "navigate",
        "Sec-Fetch-Site": "none"
    }
    
    try:
        # ğŸ”§ ACÄ°L Ã‡Ã–ZÃœM: Timeout'u 15 saniyeye Ã§Ä±kar
        session = requests.Session()
        r = session.get(url, headers=headers, timeout=15, verify=False)
        print(f"ğŸ“Š TEFAS HTML Response: {r.status_code} | Content-Length: {len(r.text)}")
        
        if r.status_code == 200 and len(r.text) > 1000:  # Minimum iÃ§erik kontrolÃ¼
            html = r.text
            
            # ğŸ”§ ACÄ°L Ã‡Ã–ZÃœM: Daha esnek regex pattern'leri
            # Fiyat iÃ§in birden fazla pattern dene
            price_patterns = [
                r"Son Fiyat.*?<span>([\d,\.]+)</span>",
                r"NAV.*?<span>([\d,\.]+)</span>", 
                r"Fiyat.*?<span>([\d,\.]+)</span>",
                r"<span.*?class.*?fiyat.*?>([\d,\.]+)</span>",
                r"(\d+,\d{4})"  # Genel sayÄ± formatÄ±
            ]
            
            price = 0.0
            for pattern in price_patterns:
                match = re.search(pattern, html, re.DOTALL)
                if match:
                    price = _parse_turkish_float(match.group(1))
                    if price > 0:
                        print(f"âœ… Fiyat bulundu ({pattern}): {price}")
                        break
            
            # GÃ¼nlÃ¼k getiri iÃ§in birden fazla pattern
            daily_patterns = [
                r"GÃ¼nlÃ¼k Getiri.*?<span>(.*?)</span>",
                r"GÃ¼nlÃ¼k.*?<span>(.*?)</span>",
                r"Daily.*?<span>(.*?)</span>",
                r"<span.*?gÃ¼nlÃ¼k.*?>(.*?)</span>",
            ]
            
            daily = 0.0
            for pattern in daily_patterns:
                match = re.search(pattern, html, re.DOTALL)
                if match:
                    daily = _parse_turkish_float(match.group(1))
                    if daily != 0.0:
                        print(f"âœ… GÃ¼nlÃ¼k getiri bulundu ({pattern}): {daily}%")
                        break
            
            # YÄ±llÄ±k getiri iÃ§in pattern
            yearly = 0.0
            yearly_match = re.search(r"Son 1 YÄ±l.*?<span>(.*?)</span>", html, re.DOTALL)
            if yearly_match:
                yearly = _parse_turkish_float(yearly_match.group(1))
            
            if price > 0:
                print(f"ğŸ¯ TEFAS HTML BAÅARILI: {fund_code} - Fiyat: {price}, GÃ¼nlÃ¼k: {daily}%, YÄ±llÄ±k: {yearly}%")
                return {"price": price, "daily_pct": daily, "yearly_pct": yearly, "source": "HTML"}
            else:
                print(f"âŒ TEFAS HTML FÄ°YAT BULUNAMADI: {fund_code}")
                # HTML iÃ§eriÄŸini debug iÃ§in kaydet
                debug_path = f"debug_{fund_code}.html"
                with open(debug_path, "w", encoding="utf-8") as f:
                    f.write(html)
                print(f"ğŸ’¾ HTML iÃ§eriÄŸi kaydedildi: {debug_path}")
                
        else:
            print(f"âŒ TEFAS HTML HTTP HATA: {fund_code} - Status: {r.status_code}, Length: {len(r.text)}")
            
    except requests.exceptions.Timeout:
        print(f"â° TEFAS HTML TIMEOUT: {fund_code} - 15 saniye aÅŸÄ±ldÄ±")
    except requests.exceptions.ConnectionError:
        print(f"ğŸ”Œ TEFAS HTML BAÄLANTI HATASI: {fund_code} - Ä°nternet baÄŸlantÄ±sÄ± kontrol edilmeli")
    except Exception as e:
        print(f"âŒ TEFAS HTML GENEL HATA: {fund_code} - {str(e)}")
    
    return None

# âœ… EKLENDÄ°: TEFAS tarih parse yardÄ±mcÄ±sÄ±
def _parse_tefas_date(s: str) -> Optional[datetime]:
    s = (s or "").strip()
    if not s:
        return None

    # sÄ±k gelen formatlar
    fmts = (
        "%d.%m.%Y",
        "%d/%m/%Y",
        "%Y-%m-%d",
        "%d.%m.%Y %H:%M:%S",
        "%Y-%m-%dT%H:%M:%S",
    )

    for fmt in fmts:
        try:
            return datetime.strptime(s, fmt)
        except:
            pass

    # bazen "25.12.2025 00:00:00.000" gibi geliyor -> noktadan sonrasÄ± kÄ±rp
    try:
        s2 = s.split(".000")[0]
        return datetime.strptime(s2, "%d.%m.%Y %H:%M:%S")
    except:
        return None

def _fetch_api(fund_code: str):
    print(f"ğŸŒ TEFAS API deniyorum: {fund_code}")
    url = "https://www.tefas.gov.tr/api/DB/BindHistoryInfo"
    
    # ğŸ”§ ACÄ°L Ã‡Ã–ZÃœM: Daha gÃ¼Ã§lÃ¼ headers
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "application/json, text/plain, */*",
        "Accept-Language": "tr-TR,tr;q=0.9,en-US;q=0.8,en;q=0.7",
        "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
        "X-Requested-With": "XMLHttpRequest",
        "Origin": "https://www.tefas.gov.tr",
        "Referer": "https://www.tefas.gov.tr/",
        "Connection": "keep-alive"
    }
    
    try:
        # âœ… GÃœNCELLENDÄ°: `end` tarihi Ä°stanbul saatine gÃ¶re
        try:
            end = datetime.now(ZoneInfo("Europe/Istanbul"))
        except:
            end = datetime.now()
        start = end - timedelta(days=7)  # 5 gÃ¼n yerine 7 gÃ¼n yap
        
        payload = {
            "fontip": "YAT",
            "fonkod": fund_code.upper(),
            "bastarih": start.strftime("%d.%m.%Y"),
            "bittarih": end.strftime("%d.%m.%Y"),
        }
        
        print(f"ğŸ“¡ TEFAS API Request: {fund_code} - {start.strftime('%d.%m.%Y')} to {end.strftime('%d.%m.%Y')}")
        
        # ğŸ”§ ACÄ°L Ã‡Ã–ZÃœM: Timeout'u 15 saniyeye Ã§Ä±kar
        r = requests.post(url, data=payload, headers=headers, timeout=15, verify=False)
        print(f"ğŸ“Š TEFAS API Response: {r.status_code} | Content-Length: {len(r.text)}")
        
        if r.status_code == 200:
            try:
                response_data = r.json()
                data = response_data.get("data", [])
                print(f"ğŸ“ˆ TEFAS API Data Count: {len(data) if data else 0} records")
                
                if data and len(data) > 0:
                    # En gÃ¼ncel veriyi bul
                    valid_data = []
                    for item in data:
                        # Key isimleri TEFAS tarafÄ±nda bazen deÄŸiÅŸebiliyor
                        dt = _parse_tefas_date(
                            item.get("TARIH") or item.get("Tarih") or item.get("tarih") or ""
                        )
                        if dt:
                            valid_data.append((dt, item))
                    
                    if valid_data:
                        valid_data.sort(key=lambda x: x[0], reverse=True)  # En yeni tarih en baÅŸta
                        last_date, last_item = valid_data[0]
                        # GÃ¼venli fiyat parse
                        price = _parse_turkish_float(last_item.get("FIYAT") or last_item.get("Fiyat") or last_item.get("fiyat") or 0)
                        
                        print(f"ğŸ’° TEFAS API Son Tarih: {last_date.strftime('%d.%m.%Y')} - Fiyat: {price}")
                        
                        if price > 0:
                            print(f"ğŸ¯ TEFAS API BAÅARILI: {fund_code} - Fiyat: {price}")
                            return {
                                "price": price,
                                "daily_pct": None,   # ğŸ”´ API'den gÃ¼nlÃ¼k getiri hesaplanmaz
                                "yearly_pct": 0.0,
                                "source": "API",
                                "asof_day": last_date.strftime("%Y-%m-%d"),  # âœ… KRÄ°TÄ°K: API'den gelen gerÃ§ek tarih
                            }
                        else:
                            print(f"âŒ TEFAS API GEÃ‡ERSÄ°Z FÄ°YAT: {fund_code} - {price}")
                    else:
                        print(f"âŒ TEFAS API GEÃ‡ERLI TARÄ°H BULUNAMADI: {fund_code}")
                else:
                    print(f"âŒ TEFAS API VERI YOK: {fund_code} - BoÅŸ response")
                    
            except ValueError as e:
                print(f"âŒ TEFAS API JSON HATA: {fund_code} - {str(e)}")
                print(f"Raw Response: {r.text[:200]}...")
        else:
            print(f"âŒ TEFAS API HTTP HATA: {fund_code} - Status: {r.status_code}")
            
    except requests.exceptions.Timeout:
        print(f"â° TEFAS API TIMEOUT: {fund_code} - 15 saniye aÅŸÄ±ldÄ±")
    except requests.exceptions.ConnectionError:
        print(f"ğŸ”Œ TEFAS API BAÄLANTI HATASI: {fund_code} - Ä°nternet baÄŸlantÄ±sÄ± kontrol edilmeli")
    except Exception as e:
        print(f"âŒ TEFAS API GENEL HATA: {fund_code} - {str(e)}")
    
    return None

def fetch_fund_live(fund_code: str):
    html = _fetch_html(fund_code)
    if html:
        return html   # âœ… TEFAS sitesindeki % neyse O

    api = _fetch_api(fund_code)
    if api:
        # daily_pct API'den gelmez â†’ dokunma (ASLA 0.0 yapma)
        return api

    return None

# ============================================================
# ğŸ”¥ YENÄ°: FINTABLES & TEFAS DETAY SCRAPER (X-RAY)
# ============================================================

def _fetch_tefas_allocation(fund_code: str) -> Optional[List[Dict[str, Any]]]:
    """TEFAS'tan VarlÄ±k DaÄŸÄ±lÄ±mÄ±nÄ± (Pasta Grafik) Ã§eker"""
    print(f"ğŸ¥§ TEFAS Allocation deniyorum: {fund_code}")
    url = f"https://www.tefas.gov.tr/FonAnaliz.aspx?FonKod={fund_code.upper()}"
    headers = {"User-Agent": "Mozilla/5.0"}

    try:
        r = requests.get(url, headers=headers, timeout=10, verify=False)
        if r.status_code == 200:
            html = r.text
            # Highcharts data'sÄ±nÄ± regex ile yakala
            # series: [{ name: 'VarlÄ±k DaÄŸÄ±lÄ±mÄ±', data: [["Hisse Senedi",43.58],...] }]
            
            pattern = r"series:\s*\[\{\s*name:\s*'VarlÄ±k DaÄŸÄ±lÄ±mÄ±',\s*data:\s*(\[\[.*?\]\])"
            match = re.search(pattern, html, re.DOTALL)
            
            if match:
                json_str = match.group(1).replace("'", '"')
                try:
                    # Basit bir JS array -> Python list dÃ¶nÃ¼ÅŸÃ¼mÃ¼
                    # data: [["Hisse", 40], ["Mevduat", 60]]
                    raw_data = json.loads(json_str)
                    allocation = []
                    for item in raw_data:
                        if len(item) == 2:
                            allocation.append({"name": item[0], "value": float(item[1])})
                    return allocation
                except:
                    pass
    except Exception as e:
        print(f"âŒ TEFAS Allocation HatasÄ±: {e}")
    
    return None

def _fetch_fintables_full_details(fund_code: str) -> Optional[Dict[str, Any]]:
    """
    Fintables Scraper - GÃœÃ‡LENDÄ°RÄ°LMÄ°Å VERSÄ°YON
    """
    print(f"ğŸ’ Fintables Detay Ã‡ekiliyor: {fund_code}")
    url = f"https://fintables.com/fonlar/{fund_code.upper()}"
    
    # ğŸ›¡ï¸ Anti-Bot Headers (GerÃ§ek TarayÄ±cÄ± Gibi Davran)
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        "Accept-Language": "tr-TR,tr;q=0.9,en-US;q=0.8,en;q=0.7",
        "Referer": "https://www.google.com/",
        "Upgrade-Insecure-Requests": "1"
    }

    try:
        r = requests.get(url, headers=headers, timeout=10)
        if r.status_code != 200:
            print(f"âŒ Fintables HTTP {r.status_code}")
            return None

        soup = BeautifulSoup(r.text, "html.parser")
        
        details = {
            "positions": [],
            "increased": [],
            "decreased": [],
            "info": {"founder": "", "risk_value": 0, "mgmt_fee": "", "stopaj": ""},
            "performance_chart": []
        }

        # 1. POZÄ°SYONLAR TABLOSUNU BUL (Daha zeki yÃ¶ntem)
        all_tables = soup.find_all("table")
        
        for table in all_tables:
            txt = table.get_text().lower()
            rows = table.find_all("tr")
            if len(rows) < 2: continue

            # Bu tablonun ne tablosu olduÄŸunu baÅŸlÄ±ÄŸÄ±ndan veya Ã¼stÃ¼ndeki divden anlamaya Ã§alÄ±ÅŸ
            parent_txt = table.parent.parent.get_text().lower() if table.parent and table.parent.parent else ""
            
            parsed_rows = []
            for row in rows[1:]: # BaÅŸlÄ±ÄŸÄ± atla
                cols = row.find_all("td")
                if len(cols) >= 2:
                    # Ä°lk kolon hisse kodu, ikinci kolon oran (genelde)
                    code_cand = cols[0].get_text(strip=True).split(" ")[0] # "THYAO (TÃ¼rk Hava..)" -> "THYAO"
                    ratio_cand = cols[1].get_text(strip=True)
                    
                    # SayÄ±sal kontrol
                    try:
                        ratio_val = _parse_turkish_float(ratio_cand)
                        if len(code_cand) >= 3 and ratio_val > 0:
                            parsed_rows.append({"code": code_cand, "ratio": ratio_val})
                    except:
                        pass
            
            if not parsed_rows: continue

            if "artÄ±rÄ±lan" in parent_txt or "artÄ±rÄ±lan" in txt:
                details["increased"] = parsed_rows
            elif "azaltÄ±lan" in parent_txt or "azaltÄ±lan" in txt:
                details["decreased"] = parsed_rows
            elif "bÃ¼yÃ¼k pozisyonlar" in parent_txt or "bÃ¼yÃ¼k pozisyonlar" in txt:
                details["positions"] = parsed_rows
            else:
                # HiÃ§bir baÅŸlÄ±k uymuyorsa ama veri varsa ve ana liste boÅŸsa, bunu ana liste yap
                if not details["positions"]:
                    details["positions"] = parsed_rows

        # 2. KÃœNYE BÄ°LGÄ°LERÄ° (Risk, Kurucu vb.)
        full_text = soup.get_text(" ", strip=True)
        
        # Risk DeÄŸeri (Regex ile avla: "Risk DeÄŸeri 7")
        risk_match = re.search(r"Risk DeÄŸeri\s*[:]?\s*(\d)", full_text, re.IGNORECASE)
        if risk_match:
            details["info"]["risk_value"] = int(risk_match.group(1))
        
        # Kurucu
        founder_match = re.search(r"Kurucu\s+(.*?)(?=\s+YÄ±llÄ±k|$)", full_text, re.IGNORECASE)
        if founder_match:
            details["info"]["founder"] = founder_match.group(1).strip()

        print(f"âœ… Fintables Data: {len(details['positions'])} pozisyon, Risk: {details['info'].get('risk_value')}")
        return details

    except Exception as e:
        print(f"âŒ Fintables Error: {e}")
        return None

# ============================================================
# ğŸ”¥ YENÄ°: HÄ°SSE BAZLI AI SKORLAMA (LIVE STOCK DATA ILE)
# ============================================================
def _load_live_stocks() -> Dict[str, float]:
    """Services.py tarafÄ±ndan Ã¼retilen hisse fiyatlarÄ±nÄ± okur"""
    prices = {}
    if os.path.exists(STOCKS_LIVE_PRICES_PATH):
        try:
            with open(STOCKS_LIVE_PRICES_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
                # data formatÄ± genelde [{"symbol": "THYAO", "chgPct": 2.5}, ...] ÅŸeklindedir
                if isinstance(data, list):
                    for item in data:
                        sym = item.get("symbol", "").replace(".IS", "")
                        chg = item.get("chgPct", 0.0)
                        prices[sym] = float(chg)
                elif isinstance(data, dict) and "data" in data: # Wrapper varsa
                     for item in data["data"]:
                        sym = item.get("symbol", "").replace(".IS", "")
                        chg = item.get("chgPct", 0.0)
                        prices[sym] = float(chg)
        except:
            pass
    return prices

def calculate_ai_prediction(yearly: float, daily: float, holdings: List[Dict[str, Any]] = None):
    """
    YENÄ° NESÄ°L AI TAHMÄ°NÄ°:
    EÄŸer 'holdings' (Fintables'tan gelen hisse listesi) varsa,
    bu hisselerin CANLI piyasa deÄŸiÅŸimlerine gÃ¶re fona puan verir.
    """
    # 1. Klasik (Baz) Skor
    d_val = daily if daily is not None else 0.0
    
    direction = "NÃ–TR"
    confidence = 50
    
    # Baz puanlama (GeÃ§miÅŸ performans)
    if yearly > 40:
        confidence += 20
        direction = "POZÄ°TÄ°F"
    elif yearly < 0:
        confidence += 10
        direction = "NEGATÄ°F"

    # GÃ¼nlÃ¼k hareket (TEFAS verisi - DÃ¼nkÃ¼ kapanÄ±ÅŸ)
    if d_val > 0.1:
        if direction == "POZÄ°TÄ°F":
            confidence += 10
        elif direction == "NÃ–TR":
            direction = "POZÄ°TÄ°F"
    elif d_val < -0.1:
        if direction == "NEGATÄ°F":
            confidence += 10
        elif direction == "POZÄ°TÄ°F":
            confidence -= 15

    # 2. HÄ°SSE BAZLI CANLI SKOR (EÄŸer veri varsa)
    stock_impact = 0.0
    
    if holdings:
        live_stocks = _load_live_stocks()
        if live_stocks:
            total_w = 0
            weighted_change = 0
            
            for h in holdings:
                code = h.get("code", "")
                ratio = h.get("ratio", 0.0)
                
                # Hissenin canlÄ± deÄŸiÅŸimini bul
                live_chg = live_stocks.get(code)
                
                if live_chg is not None:
                    weighted_change += (live_chg * ratio)
                    total_w += ratio
            
            # Fonun iÃ§indeki hisselerin ortalama deÄŸiÅŸimi
            if total_w > 0:
                avg_stock_change = weighted_change / total_w
                stock_impact = avg_stock_change
                
                # Skoru gÃ¼ncelle
                if avg_stock_change > 0.5: # Hisseler bugÃ¼n coÅŸmuÅŸ
                    direction = "POZÄ°TÄ°F"
                    confidence = min(95, confidence + 15)
                elif avg_stock_change < -0.5: # Hisseler bugÃ¼n Ã§akÄ±lmÄ±ÅŸ
                    direction = "NEGATÄ°F"
                    confidence = min(95, confidence + 15)
    
    # Tahmin edilen getiri (Basit model)
    # (Hisse etkisi * 0.7) + (TEFAS dÃ¼nkÃ¼ getiri * 0.3)
    estimated_return = (stock_impact * 0.7) + (d_val * 0.3)
    
    # YÃ¶nÃ¼ estimated_return belirlesin
    if estimated_return > 0.1:
        direction = "POZÄ°TÄ°F"
    elif estimated_return < -0.1:
        direction = "NEGATÄ°F"

    return direction, confidence, estimated_return


def get_fund_data_safe(fund_code: str):
    """
    GÃœNDE 1 KEZ TEFAS + FINTABLES ENTEGRASYONLU
    """
    fund_code = fund_code.upper()
    effective_day = tefas_effective_date()

    try:
        now = datetime.now(ZoneInfo("Europe/Istanbul"))
    except:
        now = datetime.now()
    before_open = now.hour < 9 or (now.hour == 9 and now.minute < 30)
    is_weekend = now.weekday() >= 5

    cached = _PRICE_CACHE.get(fund_code)

    if not cached:
        if os.path.exists(LIVE_PRICES_PATH):
            try:
                with open(LIVE_PRICES_PATH, "r", encoding="utf-8") as f:
                    disk_raw = json.load(f)
                disk_data = disk_raw.get("data", {}) if isinstance(disk_raw, dict) else {}
                if disk_data.get(fund_code):
                    cached = disk_data[fund_code]
                    _PRICE_CACHE[fund_code] = cached
            except:
                pass

    cached_asof = (cached.get("asof_day") or "").strip() if cached else ""
    
    # Detay verisi var mÄ± kontrol et (Yeni eklenen Ã¶zellik)
    has_details = cached and "details" in cached and cached["details"].get("positions")

    is_new_fund = not cached
    force_fetch = False
    
    if is_new_fund:
        force_fetch = True
    elif not has_details: 
        # Veri var ama detay yoksa, detay Ã§ekmek iÃ§in zorla (gÃ¼nde 1 kere)
        force_fetch = True 
    elif cached_asof != effective_day:
        force_fetch = True

    if (not is_weekend) and before_open and not is_new_fund and has_details:
        force_fetch = False

    if not force_fetch and cached:
        return cached

    if not cached and not force_fetch:
        return {"nav": 0.0, "daily_return_pct": 0.0}

    with _TEFAS_LOCK:
        cached = _PRICE_CACHE.get(fund_code)
        if cached and cached.get("asof_day") == effective_day and "details" in cached and cached["details"].get("positions"):
            return cached

        print(f"ğŸš€ FORCE FETCH (X-RAY): {fund_code}")

        data = None
        if force_fetch:
            data = fetch_fund_live(fund_code)

        if data and data.get("price", 0) > 0:
            asof_day = (data.get("asof_day") or "").strip()
            if not asof_day:
                api_meta = _fetch_api(fund_code)
                asof_day = api_meta["asof_day"] if api_meta else effective_day

            safe_daily = data["daily_pct"] if data["daily_pct"] is not None else 0.0

            # ğŸ”¥ YENÄ°: DETAYLARI Ã‡EK
            # 1. Fintables'tan detaylarÄ± (Pozisyonlar, Risk vb.) al
            details = _fetch_fintables_full_details(fund_code)
            
            # 2. TEFAS'tan Allocation (Pasta Grafik) al (Yedek veya tamamlayÄ±cÄ±)
            allocation = _fetch_tefas_allocation(fund_code)
            
            if details:
                if allocation:
                     details["allocation"] = allocation # TEFAS verisi daha temiz oluyor genelde
            else:
                # Fintables baÅŸarÄ±sÄ±zsa boÅŸ obje oluÅŸtur, en azÄ±ndan allocation ekle
                details = {
                    "positions": [],
                    "info": {},
                    "allocation": allocation if allocation else []
                }

            # ğŸ”¥ YENÄ°: AI Hesapla (Pozisyon verisiyle)
            holdings = details.get("positions", [])
            dir_str, conf, est_ret = calculate_ai_prediction(data["yearly_pct"], safe_daily, holdings)

            new_data = {
                "nav": data["price"],
                "daily_return_pct": safe_daily,
                "asof_day": asof_day,
                "last_update": asof_day + " 18:30:00",
                "source": data.get("source", "HTML"),
                "details": details, # âœ… ZENGÄ°N VERÄ° EKLENDÄ°
                "ai_prediction": {
                    "direction": dir_str,
                    "confidence": conf,
                    "score": round(data["yearly_pct"] / 12, 2),
                    "estimated_return": round(est_ret, 2) # âœ… YENÄ°
                },
            }

            _PRICE_CACHE[fund_code] = new_data
            save_memory_to_disk()
            return new_data
        
        elif force_fetch and cached:
             # TEFAS ana veri baÅŸarÄ±sÄ±z ama cache var -> DetaylarÄ± gÃ¼ncellemeye Ã§alÄ±ÅŸ
             # (Opsiyonel: Sadece detay eksikse buraya dÃ¼ÅŸebilir)
             pass

    return cached if cached else {"nav": 0.0, "daily_return_pct": 0.0}

# ============================================================
# 4. MARKET DATA (BIST / USD) â€“ 15 DK
# ============================================================

def update_market_data():
    """BIST ve USD gÃ¼nceller"""
    items = []
    tickers = {"USDTRY": "USDTRY=X", "BIST100": "XU100.IS", "BIST30": "XU030.IS"}
    for c, s in tickers.items():
        try:
            t = yf.Ticker(s)
            info = t.fast_info
            p = info.last_price
            prev = info.previous_close
            pct = ((p - prev) / prev) * 100 if prev else 0.0
            items.append({"code": c, "value": round(p, 4), "change_pct": round(pct, 2)})
        except:
            items.append({"code": c, "value": 0.0, "change_pct": 0.0})

    # âœ… PATCH 2: Atomik yazma
    try:
        _atomic_write_json(MARKET_CACHE_PATH, {"asof": now_str(), "items": items})
        print(f"ğŸ”„ Market Updated: {now_str()}")
    except Exception as e:
        print(f"âŒ Market write error: {e}")
    return items

def _get_market_change_pct(code: str) -> float:
    """AI tahmin iÃ§in market yÃ¼zdesini okur (TEFAS deÄŸil)"""
    try:
        if os.path.exists(MARKET_CACHE_PATH):
            with open(MARKET_CACHE_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
            for it in data.get("items", []):
                if it.get("code") == code:
                    return float(it.get("change_pct", 0.0) or 0.0)
    except:
        pass
    return 0.0

# ============================================================
# 5. AI TAHMÄ°N (TEFAS YOK) â€“ 5 SN
# ============================================================

def get_ai_prediction_live(fund_code: str, daily_real: float) -> Dict[str, Any]:

    # ===============================
    # â° PÄ°YASA AÃ‡IK / KAPALI KONTROLÃœ
    # ===============================
    try:
        now_tr = datetime.now(ZoneInfo("Europe/Istanbul"))
    except:
        now_tr = datetime.now()

    # BIST: 09:30 â€“ 18:10 arasÄ± aÃ§Ä±k kabul edelim
    market_open = (
        (now_tr.hour > 9 or (now_tr.hour == 9 and now_tr.minute >= 30)) and
        (now_tr.hour < 18 or (now_tr.hour == 18 and now_tr.minute <= 10))
    )

    """
    ğŸ”’ Direction kilidi
    ğŸŒŠ YumuÅŸak jitter
    ğŸ§  Premium AI anchor
    TEFAS'a DOKUNMAZ
    """
    fund_code = fund_code.upper()
    now_ts = time.time()

    with _AI_LOCK:
        cached = _AI_CACHE.get(fund_code)
        
        # EÄŸer cached veri varsa ve "predicted_return_pct" yoksa (eski cache), yenile
        if cached and "predicted_return_pct" not in cached:
             cached = None

        # â›” PÄ°YASA KAPALIYSA â†’ CANLI AI KÄ°LÄ°TLENÄ°R
        if not market_open and cached:
            return cached

        # Market aÃ§Ä±ksa cache'i kÄ±salt
        try:
            now_tr = datetime.now(ZoneInfo("Europe/Istanbul"))
        except:
            now_tr = datetime.now()
        ttl = 1 if market_open else 3600  # KapalÄ±yken 1 saat kilit


        if cached and (now_ts - cached["_ts"]) < ttl:
            return cached

        # ===============================
        # MARKET VERÄ°LERÄ°
        # ===============================
        bist = _get_market_change_pct("BIST100")
        usd = _get_market_change_pct("USDTRY")

        # ===============================
        # ğŸ§  PREMIUM AI ANCHOR (TEK SATIR MANTIÄI)
        # ===============================
        master = _get_master_map_cached()
        rec = master.get(fund_code, {})
        fund_name = rec.get("name", "")
        fund_type = rec.get("type", "")

        premium = premium_build_prediction(
            fund_code=fund_code,
            fund_name=fund_name,
            fund_type_from_master=fund_type,
            daily_real_pct=daily_real,
            bist_change_pct=float(bist or 0.0),
            usd_change_pct=float(usd or 0.0),
            market_asof=now_str(),
        )
        premium_base = float(premium.get("predicted_return_pct", 0.0))

        # ===============================
        # ğŸŒŠ SOFT JITTER (Ã‡OK KÃœÃ‡ÃœK)
        # ===============================
        # deterministik (random yok)
        jitter = math.sin(now_ts / 60.0) * 0.03  # max Â±0.03

        # ===============================
        # GÃœN Ä°Ã‡Ä° DRIFT (KAPANIÅA SIFIRLANIR)
        # ===============================
        # âœ… GÃœNCELLENDÄ°: dt Ä°stanbul saatine gÃ¶re
        try:
            dt = datetime.now(ZoneInfo("Europe/Istanbul"))
        except:
            dt = datetime.now()
        minutes = dt.hour * 60 + dt.minute
        session_pos = max(0.0, min(1.0, (minutes - 570) / (1090 - 570)))
        drift = 0.12 * (1.0 - session_pos)

        # ===============================
        # ğŸ¯ FÄ°NAL TAHMÄ°N (AÄIRLIKLI)
        # ===============================
        # EÄŸer cached veride hisse bazlÄ± tahmin varsa (estimated_return), onu da kat
        fund_data = _PRICE_CACHE.get(fund_code, {})
        holdings_impact = 0.0
        if "ai_prediction" in fund_data:
             holdings_impact = fund_data["ai_prediction"].get("estimated_return", 0.0)

        # FormÃ¼l: Premium Base %60 + Holdings %30 + Daily %10
        predicted = (
            premium_base * 0.60 +
            holdings_impact * 0.30 +
            daily_real * 0.10 +
            drift * 0.05 +
            jitter
        )
        predicted = round(predicted, 2)

        # ===============================
        # ğŸ”’ DIRECTION LOCK
        # ===============================
        prev = _AI_DIRECTION_LOCK.get(fund_code)

        raw_direction = (
            "POZÄ°TÄ°F" if predicted > 0
            else "NEGATÄ°F" if predicted < 0
            else "NÃ–TR"
        )

        direction = raw_direction

        if prev:
            # yÃ¶n deÄŸiÅŸimi iÃ§in eÅŸik
            if raw_direction != prev["direction"]:
                # kÃ¼Ã§Ã¼k deÄŸiÅŸimde yÃ¶nÃ¼ KORU
                if abs(predicted) < 0.25:
                    direction = prev["direction"]
                else:
                    # yÃ¶n deÄŸiÅŸti ama TS gÃ¼ncelle
                    _AI_DIRECTION_LOCK[fund_code] = {
                        "direction": raw_direction,
                        "ts": now_ts,
                    }
            else:
                direction = prev["direction"]
        else:
            _AI_DIRECTION_LOCK[fund_code] = {
                "direction": raw_direction,
                "ts": now_ts,
            }

        confidence = int(min(95, max(10, 55 + abs(predicted) * 10)))

        out = {
            "predicted_return_pct": predicted,
            "direction": direction,
            "confidence_score": confidence,
            "asof": now_str(),
            "_ts": now_ts,
        }

        _AI_CACHE[fund_code] = out
        return out

# ============================================================
# 6. OTOMATÄ°K ZAMANLAYICI (MARKET DATA Ä°Ã‡Ä°N)
# ============================================================

def auto_market_loop():
    """Server aÃ§Ä±k olduÄŸu sÃ¼rece her 15 dakikada bir Ã§alÄ±ÅŸÄ±r"""
    while True:
        update_market_data()
        time.sleep(900)  # 15 dakika bekle

# ============================================================
# 6.5 âœ… PREMIUM AI SUMMARY (TIP Ã–ZET + TOP FONLAR)
# ============================================================

def _safe_float(v: Any, default: float = 0.0) -> float:
    try:
        if v is None:
            return default
        if isinstance(v, (int, float)):
            return float(v)
        s = str(v).strip().replace(",", ".").replace("%", "")
        return float(s) if s else default
    except:
        return default

def _build_predictions_summary(scope: str = "portfolio") -> Dict[str, Any]:
    """
    scope:
      - "portfolio": sadece portfÃ¶ydeki fonlar
      - "all": funds_master iÃ§indeki tÃ¼m fonlar (1269 fon olabilir)
    """
    # market snapshot (premium_ai yardÄ±mcÄ±larÄ± ile)
    snap = read_market_snapshot(MARKET_CACHE_PATH)
    bist = market_change_pct(snap, "BIST100")
    usd = market_change_pct(snap, "USDTRY")
    market_asof = str(snap.get("asof") or "")

    master = _get_master_map_cached()

    # universe seÃ§imi
    codes: List[str] = []

    if scope == "all":
        codes = list(master.keys())
    else:
        # portfolio
        if os.path.exists(PORTFOLIO_PATH):
            try:
                with open(PORTFOLIO_PATH, "r", encoding="utf-8") as f:
                    raw = json.load(f)
                for pos in raw.get("positions", []):
                    c = str(pos.get("code") or "").upper().strip()
                    if c:
                        codes.append(c)
            except:
                codes = []
        # fallback: boÅŸsa, yine de birkaÃ§ Ã¶rnek dÃ¶ndÃ¼rme yerine boÅŸ dÃ¶necek

    # compute predictions
    items: List[Dict[str, Any]] = []
    by_type_acc: Dict[str, Dict[str, float]] = {}  # type -> {sum, cnt}

    for code in codes:
        rec = master.get(code, {}) if isinstance(master, dict) else {}
        fund_name = str(rec.get("name") or "")
        fund_type = str(rec.get("type") or "")

        # ğŸ“Œ DÃœZELME 2: RAM cache yoksa Disk cache'ten oku (persistence)
        info = _PRICE_CACHE.get(code)
        
        if not info:
            # ğŸ”´ RAM boÅŸsa disk cache'ten oku
            if os.path.exists(LIVE_PRICES_PATH):
                try:
                    with open(LIVE_PRICES_PATH, "r", encoding="utf-8") as f:
                        disk_raw = json.load(f)
                    disk_data = disk_raw.get("data", {})
                    info = disk_data.get(code, {})
                except:
                    info = {}

        daily_real = _safe_float(info.get("daily_return_pct") if info else 0.0, 0.0)

        out = premium_build_prediction(
            fund_code=code,
            fund_name=fund_name,
            fund_type_from_master=fund_type,
            daily_real_pct=daily_real,
            bist_change_pct=float(bist or 0.0),
            usd_change_pct=float(usd or 0.0),
            market_asof=market_asof,
        )

        pred = _safe_float(out.get("predicted_return_pct"), 0.0)
        conf = int(_safe_float(out.get("confidence_score"), 50))
        direction = str(out.get("direction") or "NOTR")
        typ = str(out.get("meta", {}).get("fund_type") or fund_type or "DIGER")

        items.append({
            "code": code,
            "name": fund_name,
            "type": typ,
            "predicted_return_pct": round(pred, 2),
            "confidence_score": conf,
            "direction": direction,
        })

        acc = by_type_acc.get(typ)
        if not acc:
            by_type_acc[typ] = {"sum": pred, "cnt": 1.0}
        else:
            acc["sum"] += pred
            acc["cnt"] += 1.0

    # by_type averages
    by_type = []
    for t, acc in by_type_acc.items():
        cnt = int(acc["cnt"])
        avg = (acc["sum"] / acc["cnt"]) if acc["cnt"] else 0.0
        by_type.append({
            "type": t,
            "avg_pct": round(avg, 2),
            "count": cnt,
        })

    # sort by avg desc (kurumsal gÃ¶rÃ¼nÃ¼m)
    by_type.sort(key=lambda x: x.get("avg_pct", 0.0), reverse=True)

    # top funds: pred desc, conf >= 65
    top_funds = [x for x in items if int(x.get("confidence_score", 0)) >= 65]
    top_funds.sort(key=lambda x: (x.get("predicted_return_pct", 0.0), x.get("confidence_score", 0)), reverse=True)
    
    # âœ… FIX 3: Fallback mekanizmasÄ± (Liste asla boÅŸ dÃ¶nmesin)
    if not top_funds:
        items.sort(key=lambda x: (x.get("predicted_return_pct", 0.0), x.get("confidence_score", 0)), reverse=True)
        top_funds = items[:8]
    else:
        top_funds = top_funds[:8]

    return {
        "status": "success",
        "asof": now_str(),
        "scope": scope,
        "market": {
            "asof": market_asof,
            "bist_change_pct": round(float(bist or 0.0), 2),
            "usd_change_pct": round(float(usd or 0.0), 2),
        },
        "by_type": by_type,
        "top_funds": top_funds,
        "count": len(items),
    }

# ============================================================
# 7. YENÄ°: OTOMATÄ°K GÃœNCELLEME SÄ°STEMÄ°
# ============================================================

def update_newly_added_funds(fund_codes: List[str]):
    """
    Yeni eklenen fonlarÄ± hemen gÃ¼nceller
    """
    if not fund_codes:
        return
        
    print(f"ğŸš€ Yeni eklenen fonlar gÃ¼ncelleniyor: {', '.join(fund_codes)}")
    
    for i, code in enumerate(fund_codes, 1):
        print(f"ğŸ“ˆ [{i}/{len(fund_codes)}] GÃ¼ncelleniyor: {code}")
        try:
            result = get_fund_data_safe(code)
            if result and result.get("nav", 0) > 0:
                print(f"âœ… {code} baÅŸarÄ±yla gÃ¼ncellendi - Fiyat: {result['nav']:.4f}")
            else:
                print(f"âŒ {code} gÃ¼ncellenemedi - Veri alÄ±namadÄ±")
        except Exception as e:
            print(f"ğŸ’¥ {code} gÃ¼ncelleme hatasÄ±: {str(e)}")
        
        time.sleep(0.4)  # Ban korumasÄ±
    
    print(f"ğŸ¯ TÃ¼m yeni fonlar iÅŸlendi: {len(fund_codes)} adet")

# âœ… GÃœNCELLENDÄ°: "Any" yerine tÃ¼m portfÃ¶yÃ¼n gÃ¼ncel olup olmadÄ±ÄŸÄ±nÄ± kontrol eder ve timezone dÃ¼zeltmesi
def maybe_update_portfolio_funds():
    """
    09:30 sonrasÄ± portfÃ¶y fonlarÄ±nÄ± GÃœNDE 1 KEZ (effective_day bazlÄ±) tamamlar.
    """
    # EÄŸer server restart olmuÅŸsa (RAM cache boÅŸsa) gÃ¼nlÃ¼k kilidi resetle
    if not _PRICE_CACHE:
        _save_portfolio_update_day("")

    try:
        now = datetime.now(ZoneInfo("Europe/Istanbul"))
    except:
        now = datetime.now()
    if now.hour < 9 or (now.hour == 9 and now.minute < 30):
        return

    today = now.strftime("%Y-%m-%d")
    effective_day = tefas_effective_date()
    run_day = effective_day  # âœ… State anahtarÄ± bu olmalÄ±

    with _PORTFOLIO_UPDATE_LOCK:
        # PortfÃ¶y yoksa state yazÄ±p Ã§Ä±k
        if not os.path.exists(PORTFOLIO_PATH):
            _save_portfolio_update_day(run_day)
            return

        # PortfÃ¶y kodlarÄ±nÄ± oku
        try:
            with open(PORTFOLIO_PATH, "r", encoding="utf-8") as f:
                raw = json.load(f)
            codes = [
                (p.get("code") or "").upper().strip()
                for p in raw.get("positions", [])
                if p.get("code")
            ]
        except Exception as e:
            print(f"âŒ PortfÃ¶y okuma hata: {e}")
            return

        # âœ… DEBUG PRINT (Ä°STENÄ°LEN)
        print(f"ğŸ§ª Portfolio codes={len(codes)} | state_day={_load_portfolio_update_day()} | today={today} | effective_day={effective_day}")

        # Eksikleri bul (RAM + disk Ã¼zerinden)
        missing = _missing_codes_for_day(codes, effective_day)
        last_day = _load_portfolio_update_day()

        # âœ… SADECE: run_day state yazÄ±lmÄ±ÅŸ VE portfÃ¶yde eksik yoksa erken Ã§Ä±k
        if last_day == run_day and not missing:
            return

        # Eksik yoksa state'i dÃ¼zelt ve Ã§Ä±k
        if not missing:
            _save_portfolio_update_day(run_day)
            return

        print(f"ğŸ”„ PortfÃ¶y auto-update: {len(missing)}/{len(codes)} fon eksik, gÃ¼ncellenecek. effective_day={effective_day}")

        # Sadece eksikleri gÃ¼ncelle
        for code in missing:
            try:
                get_fund_data_safe(code)
            except Exception as e:
                print(f"âŒ PortfÃ¶y update hata ({code}): {e}")
            time.sleep(0.4)  # ğŸ”’ BAN KORUMASI

        # GÃ¼n bitti (portfÃ¶y tamamlandÄ± mÄ± kontrol et) â†’ state yaz
        missing2 = _missing_codes_for_day(codes, effective_day)
        if not missing2:
            _save_portfolio_update_day(run_day)
            print(f"âœ… PortfÃ¶y fonlarÄ± tamamlandÄ± ({run_day})")
        else:
            print(f"âš ï¸ PortfÃ¶y fonlarÄ± kÄ±smi kaldÄ±: {len(missing2)} fon hÃ¢lÃ¢ eksik; sonraki istekte tekrar denenecek.")

# âœ… GÃœNCELLENDÄ°: "Any" yerine tÃ¼m canlÄ± listenin gÃ¼ncel olup olmadÄ±ÄŸÄ±nÄ± kontrol eder ve timezone dÃ¼zeltmesi
def maybe_update_live_list_funds():
    """
    09:30 sonrasÄ± canlÄ± listedeki fonlarÄ± GÃœNDE 1 KEZ (effective_day bazlÄ±) tamamlar.
    """
    # EÄŸer server restart olmuÅŸsa (RAM cache boÅŸsa) gÃ¼nlÃ¼k kilidi resetle
    if not _PRICE_CACHE:
        _save_live_list_update_day("")

    try:
        now = datetime.now(ZoneInfo("Europe/Istanbul"))
    except:
        now = datetime.now()
    if now.hour < 9 or (now.hour == 9 and now.minute < 30):
        return

    today = now.strftime("%Y-%m-%d")
    effective_day = tefas_effective_date()
    run_day = effective_day  # âœ… State anahtarÄ± bu olmalÄ±

    with _LIVE_LIST_UPDATE_LOCK:
        # Liste yoksa state yazÄ±p Ã§Ä±k
        if not os.path.exists(LIVE_LIST_PATH):
            _save_live_list_update_day(run_day)
            return

        # Liste kodlarÄ±nÄ± oku
        try:
            with open(LIVE_LIST_PATH, "r", encoding="utf-8") as f:
                raw = json.load(f)
            codes = [
                (item.get("code") or "").upper().strip()
                for item in raw.get("items", [])
                if item.get("code")
            ]
        except Exception as e:
            print(f"âŒ CanlÄ± liste okuma hata: {e}")
            return

        # Eksikleri bul
        missing = _missing_codes_for_day(codes, effective_day)
        last_day = _load_live_list_update_day()

        # âœ… SADECE: run_day state yazÄ±lmÄ±ÅŸ VE listede eksik yoksa erken Ã§Ä±k
        if last_day == run_day and not missing:
            return

        # Eksik yoksa state'i dÃ¼zelt ve Ã§Ä±k
        if not missing:
            _save_live_list_update_day(run_day)
            return

        print(f"ğŸ”„ CanlÄ± liste auto-update: {len(missing)}/{len(codes)} fon eksik, gÃ¼ncellenecek. effective_day={effective_day}")

        # Sadece eksikleri gÃ¼ncelle
        for code in missing:
            try:
                get_fund_data_safe(code)
            except Exception as e:
                print(f"âŒ CanlÄ± liste update hata ({code}): {e}")
            time.sleep(0.4)  # Ban korumasÄ±

        # GÃ¼n bitti mi kontrol et â†’ state yaz
        missing2 = _missing_codes_for_day(codes, effective_day)
        if not missing2:
            _save_live_list_update_day(run_day)
            print(f"âœ… CanlÄ± liste fonlarÄ± tamamlandÄ± ({run_day})")
        else:
            print(f"âš ï¸ CanlÄ± liste fonlarÄ± kÄ±smi kaldÄ±: {len(missing2)} fon hÃ¢lÃ¢ eksik; sonraki istekte tekrar denenecek.")

# ============================================================
# 8. API ENDPOINTS
# ============================================================

@router.get("/admin/refresh")
def api_refresh():
    m = update_market_data()
    return {"status": "success", "message": "Piyasa GÃ¼ncellendi.", "market": m}

@router.get("/market")
def api_market():
    data = {"items": []}
    if os.path.exists(MARKET_CACHE_PATH):
        try:
            with open(MARKET_CACHE_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
        except:
            pass
    return {"status": "success", "data": {"market": data}}

@router.get("/predictions/summary")
def api_predictions_summary(scope: str = "portfolio"):
    """
    âœ… Yeni endpoint:
      GET /funds/predictions/summary?scope=portfolio
      GET /funds/predictions/summary?scope=all

    DÃ¶ner:
      by_type: tip bazlÄ± ortalamalar
      top_funds: gÃ¼Ã§lÃ¼ fonlar listesi
    """
    global _PRED_SUMMARY_CACHE, _PRED_SUMMARY_TS
    scope = (scope or "portfolio").strip().lower()
    if scope not in ("portfolio", "all"):
        scope = "portfolio"

    # âœ… PATCH 3.4: 15 sn cache (scope bazlÄ±)
    with _PRED_SUMMARY_LOCK:
        ts = time.time()
        cached = _PRED_SUMMARY_CACHE.get(scope)
        last_ts = _PRED_SUMMARY_TS.get(scope, 0.0)
        if cached and (ts - last_ts) < _PRED_SUMMARY_TTL_SEC:
            return cached

    data = _build_predictions_summary(scope=scope)

    # âœ… PATCH 3.6: TS scope bazlÄ± update
    with _PRED_SUMMARY_LOCK:
        _PRED_SUMMARY_CACHE[scope] = data
        _PRED_SUMMARY_TS[scope] = time.time()

    return data

@router.get("/portfolio")
def api_portfolio():
    # ğŸ”¥ 09:30 sonrasÄ± otomatik portfÃ¶y gÃ¼ncelleme
    maybe_update_portfolio_funds()

    if os.path.exists(PORTFOLIO_PATH):
        try:
            with open(PORTFOLIO_PATH, "r", encoding="utf-8") as f:
                raw_portfolio = json.load(f)
        except:
            raw_portfolio = {"positions": []}
    else:
        raw_portfolio = {"positions": []}

    result_list = []
    for pos in raw_portfolio.get("positions", []):
        code = (pos.get("code") or "").upper().strip()
        if not code:
            continue
        qty = float(pos.get("quantity", 0) or 0)

        # TEFAÅ cacheli gerÃ§ek veri (gÃ¼nde 1 kere)
        info = get_fund_data_safe(code)
        daily_real = float(info.get("daily_return_pct", 0.0) or 0.0)

        # AI tahmin (sadece yÃ¶n iÃ§in)
        ai = get_ai_prediction_live(code, daily_real)

        # ğŸ¯ Ã‡Ã–ZÃœM: Mobil app'in beklediÄŸi alanlarÄ± gerÃ§ek TEFAÅ verilerine baÄŸla
        result_list.append({
            "code": code,
            "quantity": qty,
            "nav": info.get("nav", 0.0),
            "daily_return_pct": daily_real,                    # âœ… TEFAÅ gerÃ§ek %
            
            # ğŸ¯ Ã‡Ã–ZÃœM: Mobil'in predicted_return_pct alanÄ±na AI TAHMÄ°NÄ° koy (Fix 2)
            "predicted_return_pct": ai.get("predicted_return_pct", daily_real), 
            "confidence_score": ai.get("confidence_score", 50),
            "direction": ai.get("direction", "NÃ–TR"),
            
            "value": qty * float(info.get("nav", 0.0) or 0.0),

            # ESKÄ° alanÄ± koru (mevcut sistemle uyumlu)
            "prediction": info.get("ai_prediction", {}),
        })

    return {"status": "success", "data": result_list}

@router.post("/portfolio/set")
def api_pset(payload: Dict[str, Any]):
    """
    payload: {"positions":[{"code":"AFT","quantity":10}, ...]}
    
    YENÄ°: Fon eklendiÄŸinde otomatik gÃ¼ncelleme
    """
    try:
        positions = payload.get("positions", [])
        
        # âœ… YENÄ°: Ã–nceki fon kodlarÄ±nÄ± oku
        previous_codes = _get_portfolio_codes()
        
        # PortfÃ¶yÃ¼ kaydet
        with open(PORTFOLIO_PATH, "w", encoding="utf-8") as f:
            json.dump({"asof": now_str(), "positions": positions}, f, ensure_ascii=False, indent=2)
        
        # âœ… YENÄ°: Yeni eklenen fonlarÄ± tespit et ve gÃ¼ncelle
        current_codes = [str(pos.get("code") or "").upper().strip() for pos in positions if pos.get("code")]
        new_funds = _get_newly_added_funds(previous_codes, current_codes)
        
        if new_funds:
            print(f"ğŸ†• Yeni fonlar tespit edildi: {', '.join(new_funds)}")
            update_newly_added_funds(new_funds)
        
    except:
        pass
    return {"status": "success"}

@router.get("/list")
def api_list():
    if os.path.exists(FUNDS_MASTER_PATH):
        try:
            with open(FUNDS_MASTER_PATH, "r", encoding="utf-8") as f:
                master = json.load(f)
        except:
            master = []
    else:
        master = []
    return {"status": "success", "data": {"items": master}}

@router.get("/live-list")
def api_live_list():
    """
    âœ… YENÄ°: CanlÄ± liste endpoint'i
    09:30 sonrasÄ± otomatik gÃ¼ncelleme yapar
    """
    # 09:30 sonrasÄ± otomatik canlÄ± liste gÃ¼ncelleme
    maybe_update_live_list_funds()
    
    if os.path.exists(LIVE_LIST_PATH):
        try:
            with open(LIVE_LIST_PATH, "r", encoding="utf-8") as f:
                raw_list = json.load(f)
        except:
            raw_list = {"items": []}
    else:
        raw_list = {"items": []}

    result_list = []
    for item in raw_list.get("items", []):
        code = (item.get("code") or "").upper().strip()
        if not code:
            continue

        # TEFAÅ cacheli gerÃ§ek veri (gÃ¼nde 1 kere)
        info = get_fund_data_safe(code)
        daily_real = float(info.get("daily_return_pct", 0.0) or 0.0)

        # AI tahmin
        ai = get_ai_prediction_live(code, daily_real)

        result_list.append({
            "code": code,
            "name": item.get("name", ""),
            "nav": info.get("nav", 0.0),
            "daily_return_pct": daily_real,
            "predicted_return_pct": ai.get("predicted_return_pct", daily_real),
            "confidence_score": ai.get("confidence_score", 50),
            "direction": ai.get("direction", "NÃ–TR"),
            "type": item.get("type", ""),
        })

    return {"status": "success", "data": result_list}

@router.post("/live-list/set")
def api_live_list_set(payload: Dict[str, Any]):
    """
    payload: {"items":[{"code":"AFT","name":"..."}, ...]}
    
    YENÄ°: CanlÄ± listeye fon eklendiÄŸinde otomatik gÃ¼ncelleme
    """
    try:
        items = payload.get("items", [])
        
        # âœ… YENÄ°: Ã–nceki fon kodlarÄ±nÄ± oku
        previous_codes = _get_live_list_codes()
        
        # CanlÄ± listeyi kaydet
        with open(LIVE_LIST_PATH, "w", encoding="utf-8") as f:
            json.dump({"asof": now_str(), "items": items}, f, ensure_ascii=False, indent=2)
        
        # âœ… YENÄ°: Yeni eklenen fonlarÄ± tespit et ve gÃ¼ncelle
        current_codes = [str(item.get("code") or "").upper().strip() for item in items if item.get("code")]
        new_funds = _get_newly_added_funds(previous_codes, current_codes)
        
        if new_funds:
            print(f"ğŸ†• CanlÄ± listeye yeni fonlar eklendi: {', '.join(new_funds)}")
            update_newly_added_funds(new_funds)
        
    except:
        pass
    return {"status": "success"}

@router.get("/detail/{code}")
def api_detail(code: str):
    # Detayda cacheli hÄ±zlÄ± dÃ¶n (gÃ¼nde 1 TEFAS)
    info = get_fund_data_safe(code)
    if info.get("nav", 0) > 0:
        daily_real = float(info.get("daily_return_pct", 0.0) or 0.0)
        ai = get_ai_prediction_live(code.upper(), daily_real)
        
        # EÄŸer Fintables'tan gelen detaylÄ± AI skoru varsa (hisse bazlÄ±), onu da ekle
        predicted_return = ai.get("predicted_return_pct", daily_real)
        if "ai_prediction" in info and "estimated_return" in info["ai_prediction"]:
             # Cache'teki hisse bazlÄ± skoru kullanabiliriz, ama live market data daha taze
             # O yÃ¼zden get_ai_prediction_live fonksiyonu zaten bunu birleÅŸtiriyor.
             pass

        return {
            "status": "success",
            "data": {
                **info,
                # ğŸ¯ Ã‡Ã–ZÃœM: Mobil kolay kullansÄ±n diye dÃ¼z alanlar (Fix 2)
                "predicted_return_pct": predicted_return,
                "confidence_score": ai.get("confidence_score", 50),
                "direction": ai.get("direction", "NÃ–TR"),
            }
        }
    return {"status": "error", "message": "Veri yok"}

# @router.get("/admin/refresh-tefas")
# def admin_refresh_tefas():
#     """
#     TEFAS toplu batch scrape.
#     Runtime API'yi etkilemez.
#     """
#     result = run_batch_scrape()
#     return {
#         "status": "success",
#         "message": "TEFAS batch scrape tamamlandÄ±",
#         "result": result
#     }

# âœ… EKLENDÄ°: Server aÃ§Ä±lÄ±ÅŸÄ±nda bootstrap gÃ¼ncellemesi
def _startup_bootstrap_updates():
    # Uvicorn import sÄ±rasÄ±nda hemen saldÄ±rmasÄ±n, biraz bekle
    time.sleep(2)

    # Server 09:30 sonrasÄ± aÃ§Ä±ldÄ±ysa anÄ±nda dene; deÄŸilse endpoint zaten tetikler.
    try:
        maybe_update_portfolio_funds()
    except Exception as e:
        print(f"âŒ Startup portfolio bootstrap hata: {e}")

    try:
        maybe_update_live_list_funds()
    except Exception as e:
        print(f"âŒ Startup live-list bootstrap hata: {e}")

# âœ… PATCH 4.2: Threadleri tek sefer baÅŸlat (reload-safe)
def _start_background_jobs_once():
    """Uvicorn reload / Ã§oklu import durumunda thread'leri tek sefer baÅŸlat."""
    global _BG_STARTED
    with _BG_LOCK:
        if _BG_STARTED:
            return
        _BG_STARTED = True

        # 1) Cache'i RAM'e yÃ¼kle
        load_cache_to_memory()

        # 2) Market loop thread
        t_market = threading.Thread(target=auto_market_loop, daemon=True)
        t_market.start()

        # 3) Startup bootstrap thread
        t_boot = threading.Thread(target=_startup_bootstrap_updates, daemon=True)
        t_boot.start()

# âœ… Import olur olmaz Ã§alÄ±ÅŸtÄ±r (ama tek sefer)
_start_background_jobs_once()
